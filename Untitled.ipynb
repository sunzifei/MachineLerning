{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ba7d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft, ifft\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d186dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20477</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20478</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20480 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3\n",
       "0     -0.049 -0.071 -0.132 -0.010\n",
       "1     -0.042 -0.073 -0.007 -0.105\n",
       "2      0.015  0.000  0.007  0.000\n",
       "3     -0.051  0.020 -0.002  0.100\n",
       "4     -0.107  0.010  0.127  0.054\n",
       "...      ...    ...    ...    ...\n",
       "20475  0.049 -0.051 -0.039 -0.044\n",
       "20476  0.037  0.061  0.115  0.007\n",
       "20477 -0.012  0.007  0.056 -0.007\n",
       "20478 -0.012  0.093  0.017 -0.044\n",
       "20479  0.020  0.076 -0.042 -0.029\n",
       "\n",
       "[20480 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('E:\\\\WorkSpace\\\\data\\\\2nd_test\\\\2004.02.12.10.32.39', header=None, sep='\\t' )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d534063f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -0.049\n",
       "1       -0.042\n",
       "2        0.015\n",
       "3       -0.051\n",
       "4       -0.107\n",
       "         ...  \n",
       "20475    0.049\n",
       "20476    0.037\n",
       "20477   -0.012\n",
       "20478   -0.012\n",
       "20479    0.020\n",
       "Name: 0, Length: 20480, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data[0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f219fbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.010195996093749996"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = test.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46dbf1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07347672493030444"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = test.std()\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f9c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "028d72c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  563,   598,   769,   817,  1099,  1857,  1994,  2051,  2074,\n",
       "         2075,  2082,  2108,  2148,  2174,  2175,  2235,  2236,  2247,\n",
       "         2413,  2859,  2939,  3283,  3292,  3345,  3536,  3876,  3890,\n",
       "         3953,  3954,  3975,  4406,  4677,  4723,  4753,  4862,  4933,\n",
       "         4934,  5191,  5254,  5361,  5625,  5798,  5799,  5806,  6063,\n",
       "         6103,  6106,  6114,  6642,  6697,  6907,  7669,  7796,  7949,\n",
       "         8196,  8378,  8380,  8416,  8418,  8831,  8943,  9016,  9018,\n",
       "         9019,  9173,  9346,  9460,  9487, 10206, 10238, 10240, 10438,\n",
       "        10463, 10521, 10992, 10996, 11072, 11222, 11530, 11564, 12117,\n",
       "        12385, 12390, 12963, 13193, 13975, 13977, 14448, 14454, 15047,\n",
       "        15839, 15881, 15888, 15931, 16201, 16355, 16558, 16843, 17145,\n",
       "        17624, 17661, 17739, 17902, 18219, 18233, 18236, 18261, 18765,\n",
       "        19115, 19156, 19197, 19198, 19318, 19420, 19874, 19876, 19877,\n",
       "        20092, 20099], dtype=int64),)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.where(abs(test-mean) > 3*std)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6c53c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ae2d349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20480.000000\n",
       "mean        -0.010196\n",
       "std          0.073477\n",
       "min         -0.386000\n",
       "25%         -0.059000\n",
       "50%         -0.010000\n",
       "75%          0.037000\n",
       "max          0.454000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b85fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bearing1</th>\n",
       "      <th>bearing2</th>\n",
       "      <th>bearing3</th>\n",
       "      <th>bearing4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>0.132</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>0.486</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>0.149</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>-0.911</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>-1.064</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2011136 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bearing1  bearing2  bearing3  bearing4\n",
       "0       -0.049    -0.071    -0.132    -0.010\n",
       "1       -0.042    -0.073    -0.007    -0.105\n",
       "2        0.015     0.000     0.007     0.000\n",
       "3       -0.051     0.020    -0.002     0.100\n",
       "4       -0.107     0.010     0.127     0.054\n",
       "...        ...       ...       ...       ...\n",
       "2043     0.132     0.039     0.139     0.059\n",
       "2044     0.486     0.056    -0.400    -0.068\n",
       "2045     0.149     0.178    -0.249    -0.100\n",
       "2046    -0.911     0.195     0.042    -0.081\n",
       "2047    -1.064    -0.063     0.010     0.020\n",
       "\n",
       "[2011136 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('E:/WorkSpace/cache/raw_data.csv', index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1a8eacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f99f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.049</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.312</td>\n",
       "      <td>-0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.083</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.073</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1      2      3      4      5      6      7      8      9     ...  \\\n",
       "0  -0.049 -0.042  0.015 -0.051 -0.107 -0.078 -0.020 -0.046 -0.063  0.068  ...   \n",
       "1  -0.059  0.000  0.100  0.090  0.039 -0.002 -0.042 -0.059  0.034 -0.002  ...   \n",
       "2   0.029 -0.044 -0.188 -0.337 -0.137  0.000  0.000 -0.110 -0.068  0.002  ...   \n",
       "3  -0.012 -0.037  0.027 -0.024  0.022  0.024  0.056  0.056  0.059 -0.012  ...   \n",
       "4   0.032 -0.098  0.029  0.022 -0.129 -0.173 -0.044  0.020 -0.032 -0.137  ...   \n",
       "5  -0.090  0.005  0.020 -0.044 -0.071 -0.017  0.032  0.085  0.078  0.032  ...   \n",
       "6  -0.032 -0.044  0.042 -0.020 -0.007 -0.002  0.024  0.098  0.063 -0.032  ...   \n",
       "7  -0.061 -0.088 -0.073 -0.022 -0.032 -0.125 -0.103  0.000  0.056  0.020  ...   \n",
       "8   0.000  0.088 -0.032  0.037  0.220  0.144  0.093  0.088 -0.029 -0.051  ...   \n",
       "9   0.049  0.098  0.061 -0.061 -0.129 -0.076  0.005 -0.027 -0.059 -0.029  ...   \n",
       "10 -0.234 -0.044  0.100  0.076  0.103  0.078  0.073  0.115  0.059 -0.015  ...   \n",
       "11 -0.132 -0.078  0.098  0.059 -0.063 -0.117 -0.029  0.007  0.103  0.029  ...   \n",
       "12  0.083  0.129  0.090  0.073  0.085  0.078  0.024  0.034  0.002  0.012  ...   \n",
       "13  0.073  0.039 -0.110 -0.046  0.056  0.017 -0.076 -0.061  0.024 -0.027  ...   \n",
       "14  0.010 -0.032 -0.066 -0.046 -0.007 -0.005 -0.046 -0.017  0.105  0.061  ...   \n",
       "15 -0.034  0.039  0.063 -0.054 -0.112  0.000  0.061 -0.054 -0.149 -0.112  ...   \n",
       "16 -0.010  0.029 -0.017 -0.066 -0.059 -0.022  0.007 -0.032 -0.020  0.107  ...   \n",
       "17  0.000  0.110  0.068  0.005 -0.112 -0.010  0.103  0.110  0.012  0.017  ...   \n",
       "18 -0.051 -0.071 -0.056 -0.134 -0.127 -0.088 -0.002 -0.005  0.085  0.034  ...   \n",
       "19 -0.007 -0.022 -0.093  0.039  0.120  0.139  0.100 -0.042 -0.076 -0.005  ...   \n",
       "\n",
       "     1014   1015   1016   1017   1018   1019   1020   1021   1022   1023  \n",
       "0   0.083  0.010 -0.010 -0.027 -0.049 -0.012 -0.076 -0.122 -0.037  0.010  \n",
       "1  -0.068  0.022  0.186  0.049  0.010  0.159  0.088 -0.027 -0.129 -0.100  \n",
       "2   0.027 -0.073 -0.120 -0.007  0.076  0.115  0.022 -0.068 -0.054 -0.034  \n",
       "3  -0.051 -0.066 -0.037 -0.002 -0.044 -0.110 -0.090 -0.042 -0.049  0.068  \n",
       "4  -0.024 -0.032  0.046  0.117  0.024 -0.061 -0.166 -0.095 -0.046 -0.149  \n",
       "5  -0.049 -0.134 -0.159 -0.061  0.117  0.042  0.044 -0.007 -0.002  0.017  \n",
       "6   0.029  0.054  0.073  0.051  0.029  0.020 -0.034 -0.032 -0.010 -0.027  \n",
       "7  -0.071 -0.078 -0.015  0.015 -0.020 -0.012  0.200  0.056  0.044 -0.098  \n",
       "8   0.000  0.037 -0.049 -0.022 -0.056  0.029  0.137  0.005 -0.066 -0.015  \n",
       "9  -0.029 -0.010  0.010  0.046 -0.012 -0.149 -0.173  0.178  0.312 -0.066  \n",
       "10 -0.120  0.005  0.117  0.046  0.002  0.051  0.068  0.071  0.012 -0.061  \n",
       "11  0.007  0.142  0.005 -0.198 -0.195  0.010  0.032  0.046  0.002 -0.068  \n",
       "12 -0.061  0.049 -0.112 -0.076  0.100  0.098 -0.005 -0.112  0.056  0.195  \n",
       "13  0.110  0.029  0.024  0.010 -0.012  0.002 -0.046 -0.056 -0.044  0.039  \n",
       "14 -0.149 -0.115 -0.007  0.017 -0.085 -0.107 -0.032  0.007 -0.068 -0.071  \n",
       "15  0.034  0.049  0.051 -0.007  0.022  0.007  0.037  0.042 -0.095 -0.061  \n",
       "16 -0.039 -0.044 -0.056  0.000 -0.100 -0.066  0.122  0.046 -0.093 -0.122  \n",
       "17 -0.046 -0.049  0.137  0.081  0.059 -0.037  0.010  0.027 -0.129 -0.149  \n",
       "18 -0.015 -0.020  0.012  0.061  0.017 -0.010 -0.037 -0.039 -0.015  0.017  \n",
       "19  0.071  0.012 -0.032 -0.029 -0.017  0.049  0.037 -0.012 -0.012  0.020  \n",
       "\n",
       "[20 rows x 1024 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(data[0]).reshape((20, 1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09f59808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0, 10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d8f20c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.iloc[:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5986f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 6, 1400)\n",
    "y = 7*np.sin(2*np.pi*200*x) + 5*np.sin(2*np.pi*400*x) + 3*np.sin(2*np.pi*600*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1710af4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x235b3bc0970>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea4c91f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x235b3d40400>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(x[0:50], y[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd8b48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft, ifft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4cccf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400\n",
      "[ 1.05231379e-11-0.j         -9.73356836e-05+0.04337599j\n",
      " -3.89366680e-04+0.0867569j  -8.76165274e-04+0.13014768j\n",
      " -1.55785210e-03+0.17355325j]\n"
     ]
    }
   ],
   "source": [
    "fft_y = fft(y)\n",
    "print(len(fft_y))\n",
    "print(fft_y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d0bdb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x235b4e223a0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 1400\n",
    "x = np.arange(N)\n",
    "abs_y = np.abs(fft_y)\n",
    "angle_y = np.angle(fft_y)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, abs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35e19025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x235b4e70c70>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, angle_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4366483",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean=[True,False]\n",
    "gender=[\"男\",\"女\"]\n",
    "color=[\"white\",\"black\",\"yellow\"]\n",
    "data=pd.DataFrame({\n",
    "    \"height\":np.random.randint(150,190,100),\n",
    "    \"weight\":np.random.randint(40,90,100),\n",
    "    \"smoker\":[boolean[x] for x in np.random.randint(0,2,100)],\n",
    "    \"gender\":[gender[x] for x in np.random.randint(0,2,100)],\n",
    "    \"age\":np.random.randint(15,90,100),\n",
    "    \"color\":[color[x] for x in np.random.randint(0,len(color),100) ]\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c5a475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>smoker</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154</td>\n",
       "      <td>53</td>\n",
       "      <td>True</td>\n",
       "      <td>女</td>\n",
       "      <td>45</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>男</td>\n",
       "      <td>46</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162</td>\n",
       "      <td>88</td>\n",
       "      <td>False</td>\n",
       "      <td>女</td>\n",
       "      <td>81</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>True</td>\n",
       "      <td>女</td>\n",
       "      <td>59</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>男</td>\n",
       "      <td>68</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>152</td>\n",
       "      <td>86</td>\n",
       "      <td>True</td>\n",
       "      <td>男</td>\n",
       "      <td>21</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>170</td>\n",
       "      <td>87</td>\n",
       "      <td>False</td>\n",
       "      <td>女</td>\n",
       "      <td>55</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>170</td>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "      <td>男</td>\n",
       "      <td>46</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>174</td>\n",
       "      <td>54</td>\n",
       "      <td>True</td>\n",
       "      <td>女</td>\n",
       "      <td>29</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>169</td>\n",
       "      <td>76</td>\n",
       "      <td>False</td>\n",
       "      <td>女</td>\n",
       "      <td>51</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    height  weight  smoker gender  age   color\n",
       "0      154      53    True      女   45   white\n",
       "1      170      50   False      男   46   white\n",
       "2      162      88   False      女   81  yellow\n",
       "3      181      88    True      女   59   black\n",
       "4      159      40   False      男   68  yellow\n",
       "..     ...     ...     ...    ...  ...     ...\n",
       "95     152      86    True      男   21   black\n",
       "96     170      87   False      女   55  yellow\n",
       "97     170      45   False      男   46   white\n",
       "98     174      54    True      女   29   black\n",
       "99     169      76   False      女   51   white\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9b4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(data):\n",
    "    return data.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b7ab06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159</td>\n",
       "      <td>40</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>152</td>\n",
       "      <td>86</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>170</td>\n",
       "      <td>87</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>170</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>174</td>\n",
       "      <td>54</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>169</td>\n",
       "      <td>76</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    height  weight  age\n",
       "0      154      53   45\n",
       "1      170      50   46\n",
       "2      162      88   81\n",
       "3      181      88   59\n",
       "4      159      40   68\n",
       "..     ...     ...  ...\n",
       "95     152      86   21\n",
       "96     170      87   55\n",
       "97     170      45   46\n",
       "98     174      54   29\n",
       "99     169      76   51\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['height', 'weight', 'age']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f3c43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "height    189\n",
       "weight     89\n",
       "age        86\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.apply(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0a46db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.apply(foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5db3ca00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "height    189\n",
       "weight     89\n",
       "age        86\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.apply(foo).interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdce6808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.apply(foo).interpolate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "804de0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159</td>\n",
       "      <td>40</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>152</td>\n",
       "      <td>86</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>170</td>\n",
       "      <td>87</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>170</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>174</td>\n",
       "      <td>54</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>169</td>\n",
       "      <td>76</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    height  weight  age\n",
       "0      154      53   45\n",
       "1      170      50   46\n",
       "2      162      88   81\n",
       "3      181      88   59\n",
       "4      159      40   68\n",
       "..     ...     ...  ...\n",
       "95     152      86   21\n",
       "96     170      87   55\n",
       "97     170      45   46\n",
       "98     174      54   29\n",
       "99     169      76   51\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0854a05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af506c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[154,  53,  45, 170,  50,  46, 162,  88,  81, 181,  88,  59, 159,\n",
       "         40,  68, 183,  48,  58, 162,  53,  20, 181,  83,  82, 179,  41,\n",
       "         84, 160,  89,  49, 154,  63,  77, 156,  49,  31, 175,  72,  17,\n",
       "        168,  55,  72, 157,  49,  85, 180,  76,  23, 160,  44],\n",
       "       [ 58, 154,  76,  29, 173,  66,  50, 154,  68,  35, 180,  76,  40,\n",
       "        167,  41,  35, 169,  41,  46, 188,  50,  78, 174,  46,  42, 150,\n",
       "         85,  62, 174,  83,  52, 186,  65,  19, 168,  81,  49, 167,  84,\n",
       "         73, 180,  73,  48, 152,  43,  25, 176,  50,  29, 172],\n",
       "       [ 81,  43, 185,  57,  27, 177,  66,  69, 184,  76,  28, 164,  54,\n",
       "         45, 178,  57,  20, 151,  42,  17, 170,  58,  55, 151,  82,  22,\n",
       "        151,  57,  52, 182,  76,  51, 162,  84,  75, 185,  87,  62, 188,\n",
       "         43,  44, 188,  75,  78, 156,  60,  22, 187,  53,  57]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values.flatten()[0:150].reshape(3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b2389bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 300 into shape (3,50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-cb6e4de45f00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 300 into shape (3,50)"
     ]
    }
   ],
   "source": [
    "data.values[0:150].reshape(3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "927789cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 7,  8,  9, 10],\n",
       "       [10, 11, 12, 13]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[1,2,3,4], [4,5,6,7], [7,8,9,10], [10, 11, 12, 13]])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8c73ed38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "798565b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aver = np.average(test, axis=1).reshape(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fb04872d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.5,  5.5,  8.5, 11.5]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "14090890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 3., 3.]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_aver = np.diff(aver)\n",
    "diff_aver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9bf1da4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_test = np.diff(test)\n",
    "diff_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d74200b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2., -2., -2.],\n",
       "       [-2., -2., -2.],\n",
       "       [-2., -2., -2.],\n",
       "       [-2., -2., -2.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_test - diff_aver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "97d1c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.abs(diff_test - diff_aver) < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d16e6221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c55456a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07ef19ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True, False,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1,1]=False\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "35babe46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf16e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   2,   3,  -4],\n",
       "       [  4,   5,  -6,  -7],\n",
       "       [  7,   8,   9, -10],\n",
       "       [ 10, -11,  12, -13]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[1,2,3,-4], [4,5,-6,-7], [7,8,9,-10], [10, -11, 12, -13]])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3a19dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4],\n",
       "       [ 7],\n",
       "       [10],\n",
       "       [13]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_max = np.abs(test).max(axis = 1).reshape((4,1))\n",
    "abs_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "240b644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25      ,  0.5       ,  0.75      , -1.        ],\n",
       "       [ 0.57142857,  0.71428571, -0.85714286, -1.        ],\n",
       "       [ 0.7       ,  0.8       ,  0.9       , -1.        ],\n",
       "       [ 0.76923077, -0.84615385,  0.92307692, -1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_data = test / abs_max\n",
    "s_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb4a795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.125     , -0.14285714,  0.35      , -0.03846154])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aver = np.average(s_data, axis=1)\n",
    "aver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "691126ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_data = np.min(s_data, axis=1)\n",
    "min_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a564b027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.125     , 0.85714286, 1.35      , 0.96153846])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aver - min_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "095d0270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.265625  , 0.73469388, 1.8225    , 0.92455621])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(aver - min_data)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2269939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.747375090568772"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((aver - min_data)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "358be1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy, scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc82320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 64\n",
    "U = list()\n",
    "rate = L / 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e59c1c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = scipy.stats.poisson(rate).rvs()\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb257af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59.47133657230145,\n",
       " 31.371221198830746,\n",
       " 44.03906461630654,\n",
       " 45.293259944736725,\n",
       " 23.13414156970886,\n",
       " 4.017819566365198,\n",
       " 46.60200626380143,\n",
       " 3.9476999011335963,\n",
       " 38.17996513923677,\n",
       " 7.008410497805436]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = list(scipy.stats.uniform(0, L).rvs(N))\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c276bc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.08076289, 0.42166996, 0.03360673, 3.07001394, 2.36039977,\n",
       "       2.00271805, 0.31410222, 0.47403285, 2.36175157, 2.13676669])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.uniform(0, 4).rvs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7305e6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.538515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.903750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.090073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.637732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.621493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13102</th>\n",
       "      <td>2.595659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13103</th>\n",
       "      <td>-0.515556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13104</th>\n",
       "      <td>-4.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13105</th>\n",
       "      <td>-2.760027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13106</th>\n",
       "      <td>-0.928521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13107 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0      2.538515\n",
       "1      0.903750\n",
       "2     -3.090073\n",
       "3     -3.637732\n",
       "4     -1.621493\n",
       "...         ...\n",
       "13102  2.595659\n",
       "13103 -0.515556\n",
       "13104 -4.364623\n",
       "13105 -2.760027\n",
       "13106 -0.928521\n",
       "\n",
       "[13107 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.read_csv('data.csv', header=None)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94c2674c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cfeadd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf2ed9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0], dtype='int64')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7c6dd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5.386824\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.abs().sort_values(by=0, ascending=False).head(100).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12553568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "np.std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a1263d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5811388300841898"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(a, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8aa46455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8257418583505538"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(a, ddof=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db715b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:253: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(a, ddof=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f20ec47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(a, ddof=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2da2e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.tsatools import lagmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46da2e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f410739d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [2., 1., 0., 0.],\n",
       "       [3., 2., 1., 0.],\n",
       "       [4., 3., 2., 1.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lagmat(a, maxlag=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88f08ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(1, 11))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8c967ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [2., 1., 0.],\n",
       "       [3., 2., 1.],\n",
       "       [4., 3., 2.],\n",
       "       [5., 4., 3.],\n",
       "       [6., 5., 4.],\n",
       "       [7., 6., 5.],\n",
       "       [8., 7., 6.],\n",
       "       [9., 8., 7.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lagmat(a, maxlag=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0567144f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,  29,  56,  90, 130, 175, 224, 276, 330, 385, 330, 276, 224,\n",
       "       175, 130,  90,  56,  29,  10])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.correlate(a, a, mode=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd0624e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2004.02.12.10.32.39',\n",
       " '2004.02.12.10.42.39',\n",
       " '2004.02.12.10.52.39',\n",
       " '2004.02.12.11.02.39',\n",
       " '2004.02.12.11.12.39',\n",
       " '2004.02.12.11.22.39',\n",
       " '2004.02.12.11.32.39',\n",
       " '2004.02.12.11.42.39',\n",
       " '2004.02.12.11.52.39',\n",
       " '2004.02.12.12.02.39',\n",
       " '2004.02.12.12.12.39',\n",
       " '2004.02.12.12.22.39',\n",
       " '2004.02.12.12.32.39',\n",
       " '2004.02.12.12.42.39',\n",
       " '2004.02.12.12.52.39',\n",
       " '2004.02.12.13.02.39',\n",
       " '2004.02.12.13.12.39',\n",
       " '2004.02.12.13.22.39',\n",
       " '2004.02.12.13.32.39',\n",
       " '2004.02.12.13.42.39',\n",
       " '2004.02.12.13.52.39',\n",
       " '2004.02.12.14.02.39',\n",
       " '2004.02.12.14.12.39',\n",
       " '2004.02.12.14.22.39',\n",
       " '2004.02.12.14.32.39',\n",
       " '2004.02.12.14.42.39',\n",
       " '2004.02.12.14.52.39',\n",
       " '2004.02.12.15.02.39',\n",
       " '2004.02.12.15.12.39',\n",
       " '2004.02.12.15.22.39',\n",
       " '2004.02.12.15.32.39',\n",
       " '2004.02.12.15.42.39',\n",
       " '2004.02.12.15.52.39',\n",
       " '2004.02.12.16.02.39',\n",
       " '2004.02.12.16.12.39',\n",
       " '2004.02.12.16.22.39',\n",
       " '2004.02.12.16.32.39',\n",
       " '2004.02.12.16.42.39',\n",
       " '2004.02.12.16.52.39',\n",
       " '2004.02.12.17.02.39',\n",
       " '2004.02.12.17.12.39',\n",
       " '2004.02.12.17.22.39',\n",
       " '2004.02.12.17.32.39',\n",
       " '2004.02.12.17.42.39',\n",
       " '2004.02.12.17.52.39',\n",
       " '2004.02.12.18.02.39',\n",
       " '2004.02.12.18.12.39',\n",
       " '2004.02.12.18.22.39',\n",
       " '2004.02.12.18.32.39',\n",
       " '2004.02.12.18.42.39',\n",
       " '2004.02.12.18.52.39',\n",
       " '2004.02.12.19.02.39',\n",
       " '2004.02.12.19.12.39',\n",
       " '2004.02.12.19.22.39',\n",
       " '2004.02.12.19.32.39',\n",
       " '2004.02.12.19.42.39',\n",
       " '2004.02.12.19.52.39',\n",
       " '2004.02.12.20.02.39',\n",
       " '2004.02.12.20.12.39',\n",
       " '2004.02.12.20.22.39',\n",
       " '2004.02.12.20.32.39',\n",
       " '2004.02.12.20.42.39',\n",
       " '2004.02.12.20.52.39',\n",
       " '2004.02.12.21.02.39',\n",
       " '2004.02.12.21.12.39',\n",
       " '2004.02.12.21.22.39',\n",
       " '2004.02.12.21.32.39',\n",
       " '2004.02.12.21.42.39',\n",
       " '2004.02.12.21.52.39',\n",
       " '2004.02.12.22.02.39',\n",
       " '2004.02.12.22.12.39',\n",
       " '2004.02.12.22.22.39',\n",
       " '2004.02.12.22.32.39',\n",
       " '2004.02.12.22.42.39',\n",
       " '2004.02.12.22.52.39',\n",
       " '2004.02.12.23.02.39',\n",
       " '2004.02.12.23.12.39',\n",
       " '2004.02.12.23.22.39',\n",
       " '2004.02.12.23.32.39',\n",
       " '2004.02.12.23.42.39',\n",
       " '2004.02.12.23.52.39',\n",
       " '2004.02.13.00.02.39',\n",
       " '2004.02.13.00.12.39',\n",
       " '2004.02.13.00.22.39',\n",
       " '2004.02.13.00.32.39',\n",
       " '2004.02.13.00.42.39',\n",
       " '2004.02.13.00.52.39',\n",
       " '2004.02.13.01.02.39',\n",
       " '2004.02.13.01.12.39',\n",
       " '2004.02.13.01.22.39',\n",
       " '2004.02.13.01.32.39',\n",
       " '2004.02.13.01.42.39',\n",
       " '2004.02.13.01.52.39',\n",
       " '2004.02.13.02.02.39',\n",
       " '2004.02.13.02.12.39',\n",
       " '2004.02.13.02.22.39',\n",
       " '2004.02.13.02.32.39',\n",
       " '2004.02.13.02.42.39',\n",
       " '2004.02.13.02.52.39',\n",
       " '2004.02.13.03.02.39',\n",
       " '2004.02.13.03.12.39',\n",
       " '2004.02.13.03.22.39',\n",
       " '2004.02.13.03.32.39',\n",
       " '2004.02.13.03.42.39',\n",
       " '2004.02.13.03.52.39',\n",
       " '2004.02.13.04.02.39',\n",
       " '2004.02.13.04.12.39',\n",
       " '2004.02.13.04.22.39',\n",
       " '2004.02.13.04.32.39',\n",
       " '2004.02.13.04.42.39',\n",
       " '2004.02.13.04.52.39',\n",
       " '2004.02.13.05.02.39',\n",
       " '2004.02.13.05.12.39',\n",
       " '2004.02.13.05.22.39',\n",
       " '2004.02.13.05.32.39',\n",
       " '2004.02.13.05.42.39',\n",
       " '2004.02.13.05.52.39',\n",
       " '2004.02.13.06.02.39',\n",
       " '2004.02.13.06.12.39',\n",
       " '2004.02.13.06.22.39',\n",
       " '2004.02.13.06.32.39',\n",
       " '2004.02.13.06.42.39',\n",
       " '2004.02.13.06.52.39',\n",
       " '2004.02.13.07.02.39',\n",
       " '2004.02.13.07.12.39',\n",
       " '2004.02.13.07.22.39',\n",
       " '2004.02.13.07.32.39',\n",
       " '2004.02.13.07.42.39',\n",
       " '2004.02.13.07.52.39',\n",
       " '2004.02.13.08.02.39',\n",
       " '2004.02.13.08.12.39',\n",
       " '2004.02.13.08.22.39',\n",
       " '2004.02.13.08.32.39',\n",
       " '2004.02.13.08.42.39',\n",
       " '2004.02.13.08.52.39',\n",
       " '2004.02.13.09.02.39',\n",
       " '2004.02.13.09.12.39',\n",
       " '2004.02.13.09.22.39',\n",
       " '2004.02.13.09.32.39',\n",
       " '2004.02.13.09.42.39',\n",
       " '2004.02.13.09.52.39',\n",
       " '2004.02.13.10.02.39',\n",
       " '2004.02.13.10.12.39',\n",
       " '2004.02.13.10.22.39',\n",
       " '2004.02.13.10.32.39',\n",
       " '2004.02.13.10.42.39',\n",
       " '2004.02.13.10.52.39',\n",
       " '2004.02.13.11.02.39',\n",
       " '2004.02.13.11.12.39',\n",
       " '2004.02.13.11.22.39',\n",
       " '2004.02.13.11.32.39',\n",
       " '2004.02.13.11.42.39',\n",
       " '2004.02.13.11.52.39',\n",
       " '2004.02.13.12.02.39',\n",
       " '2004.02.13.12.12.39',\n",
       " '2004.02.13.12.22.39',\n",
       " '2004.02.13.12.32.39',\n",
       " '2004.02.13.12.42.39',\n",
       " '2004.02.13.12.52.39',\n",
       " '2004.02.13.13.02.39',\n",
       " '2004.02.13.13.12.39',\n",
       " '2004.02.13.13.22.39',\n",
       " '2004.02.13.13.32.39',\n",
       " '2004.02.13.13.42.39',\n",
       " '2004.02.13.13.52.39',\n",
       " '2004.02.13.14.02.39',\n",
       " '2004.02.13.14.12.39',\n",
       " '2004.02.13.14.22.39',\n",
       " '2004.02.13.14.32.39',\n",
       " '2004.02.13.14.42.39',\n",
       " '2004.02.13.14.52.39',\n",
       " '2004.02.13.15.02.39',\n",
       " '2004.02.13.15.12.39',\n",
       " '2004.02.13.15.22.39',\n",
       " '2004.02.13.15.32.39',\n",
       " '2004.02.13.15.42.39',\n",
       " '2004.02.13.15.52.39',\n",
       " '2004.02.13.16.02.39',\n",
       " '2004.02.13.16.12.39',\n",
       " '2004.02.13.16.22.39',\n",
       " '2004.02.13.16.32.39',\n",
       " '2004.02.13.16.42.39',\n",
       " '2004.02.13.16.52.39',\n",
       " '2004.02.13.17.02.39',\n",
       " '2004.02.13.17.12.39',\n",
       " '2004.02.13.17.22.39',\n",
       " '2004.02.13.17.32.39',\n",
       " '2004.02.13.17.42.39',\n",
       " '2004.02.13.17.52.39',\n",
       " '2004.02.13.18.02.39',\n",
       " '2004.02.13.18.12.39',\n",
       " '2004.02.13.18.22.39',\n",
       " '2004.02.13.18.32.39',\n",
       " '2004.02.13.18.42.39',\n",
       " '2004.02.13.18.52.39',\n",
       " '2004.02.13.19.02.39',\n",
       " '2004.02.13.19.12.39',\n",
       " '2004.02.13.19.22.39',\n",
       " '2004.02.13.19.32.39',\n",
       " '2004.02.13.19.42.39',\n",
       " '2004.02.13.19.52.39',\n",
       " '2004.02.13.20.02.39',\n",
       " '2004.02.13.20.12.39',\n",
       " '2004.02.13.20.22.39',\n",
       " '2004.02.13.20.32.39',\n",
       " '2004.02.13.20.42.39',\n",
       " '2004.02.13.20.52.39',\n",
       " '2004.02.13.21.02.39',\n",
       " '2004.02.13.21.12.39',\n",
       " '2004.02.13.21.22.39',\n",
       " '2004.02.13.21.32.39',\n",
       " '2004.02.13.21.42.39',\n",
       " '2004.02.13.21.52.39',\n",
       " '2004.02.13.22.02.39',\n",
       " '2004.02.13.22.12.39',\n",
       " '2004.02.13.22.22.39',\n",
       " '2004.02.13.22.32.39',\n",
       " '2004.02.13.22.42.39',\n",
       " '2004.02.13.22.52.39',\n",
       " '2004.02.13.23.02.39',\n",
       " '2004.02.13.23.12.39',\n",
       " '2004.02.13.23.22.39',\n",
       " '2004.02.13.23.32.39',\n",
       " '2004.02.13.23.42.39',\n",
       " '2004.02.13.23.52.39',\n",
       " '2004.02.14.00.02.39',\n",
       " '2004.02.14.00.12.39',\n",
       " '2004.02.14.00.22.39',\n",
       " '2004.02.14.00.32.39',\n",
       " '2004.02.14.00.42.39',\n",
       " '2004.02.14.00.52.39',\n",
       " '2004.02.14.01.02.39',\n",
       " '2004.02.14.01.12.39',\n",
       " '2004.02.14.01.22.39',\n",
       " '2004.02.14.01.32.39',\n",
       " '2004.02.14.01.42.39',\n",
       " '2004.02.14.01.52.39',\n",
       " '2004.02.14.02.02.39',\n",
       " '2004.02.14.02.12.39',\n",
       " '2004.02.14.02.22.39',\n",
       " '2004.02.14.02.32.39',\n",
       " '2004.02.14.02.42.39',\n",
       " '2004.02.14.02.52.39',\n",
       " '2004.02.14.03.02.39',\n",
       " '2004.02.14.03.12.39',\n",
       " '2004.02.14.03.22.39',\n",
       " '2004.02.14.03.32.39',\n",
       " '2004.02.14.03.42.39',\n",
       " '2004.02.14.03.52.39',\n",
       " '2004.02.14.04.02.39',\n",
       " '2004.02.14.04.12.39',\n",
       " '2004.02.14.04.22.39',\n",
       " '2004.02.14.04.32.39',\n",
       " '2004.02.14.04.42.39',\n",
       " '2004.02.14.04.52.39',\n",
       " '2004.02.14.05.02.39',\n",
       " '2004.02.14.05.12.39',\n",
       " '2004.02.14.05.22.39',\n",
       " '2004.02.14.05.32.39',\n",
       " '2004.02.14.05.42.39',\n",
       " '2004.02.14.05.52.39',\n",
       " '2004.02.14.06.02.39',\n",
       " '2004.02.14.06.12.39',\n",
       " '2004.02.14.06.22.39',\n",
       " '2004.02.14.06.32.39',\n",
       " '2004.02.14.06.42.39',\n",
       " '2004.02.14.06.52.39',\n",
       " '2004.02.14.07.02.39',\n",
       " '2004.02.14.07.12.39',\n",
       " '2004.02.14.07.22.39',\n",
       " '2004.02.14.07.32.39',\n",
       " '2004.02.14.07.42.39',\n",
       " '2004.02.14.07.52.39',\n",
       " '2004.02.14.08.02.39',\n",
       " '2004.02.14.08.12.39',\n",
       " '2004.02.14.08.22.39',\n",
       " '2004.02.14.08.32.39',\n",
       " '2004.02.14.08.42.39',\n",
       " '2004.02.14.08.52.39',\n",
       " '2004.02.14.09.02.39',\n",
       " '2004.02.14.09.12.39',\n",
       " '2004.02.14.09.22.39',\n",
       " '2004.02.14.09.32.39',\n",
       " '2004.02.14.09.42.39',\n",
       " '2004.02.14.09.52.39',\n",
       " '2004.02.14.10.02.39',\n",
       " '2004.02.14.10.12.39',\n",
       " '2004.02.14.10.22.39',\n",
       " '2004.02.14.10.32.39',\n",
       " '2004.02.14.10.42.39',\n",
       " '2004.02.14.10.52.39',\n",
       " '2004.02.14.11.02.39',\n",
       " '2004.02.14.11.12.39',\n",
       " '2004.02.14.11.22.39',\n",
       " '2004.02.14.11.32.39',\n",
       " '2004.02.14.11.42.39',\n",
       " '2004.02.14.11.52.39',\n",
       " '2004.02.14.12.02.39',\n",
       " '2004.02.14.12.12.39',\n",
       " '2004.02.14.12.22.39',\n",
       " '2004.02.14.12.32.39',\n",
       " '2004.02.14.12.42.39',\n",
       " '2004.02.14.12.52.39',\n",
       " '2004.02.14.13.02.39',\n",
       " '2004.02.14.13.12.39',\n",
       " '2004.02.14.13.22.39',\n",
       " '2004.02.14.13.32.39',\n",
       " '2004.02.14.13.42.39',\n",
       " '2004.02.14.13.52.39',\n",
       " '2004.02.14.14.02.39',\n",
       " '2004.02.14.14.12.39',\n",
       " '2004.02.14.14.22.39',\n",
       " '2004.02.14.14.32.39',\n",
       " '2004.02.14.14.42.39',\n",
       " '2004.02.14.14.52.39',\n",
       " '2004.02.14.15.02.39',\n",
       " '2004.02.14.15.12.39',\n",
       " '2004.02.14.15.22.39',\n",
       " '2004.02.14.15.32.39',\n",
       " '2004.02.14.15.42.39',\n",
       " '2004.02.14.15.52.39',\n",
       " '2004.02.14.16.02.39',\n",
       " '2004.02.14.16.12.39',\n",
       " '2004.02.14.16.22.39',\n",
       " '2004.02.14.16.32.39',\n",
       " '2004.02.14.16.42.39',\n",
       " '2004.02.14.16.52.39',\n",
       " '2004.02.14.17.02.39',\n",
       " '2004.02.14.17.12.39',\n",
       " '2004.02.14.17.22.39',\n",
       " '2004.02.14.17.32.39',\n",
       " '2004.02.14.17.42.39',\n",
       " '2004.02.14.17.52.39',\n",
       " '2004.02.14.18.02.39',\n",
       " '2004.02.14.18.12.39',\n",
       " '2004.02.14.18.22.39',\n",
       " '2004.02.14.18.32.39',\n",
       " '2004.02.14.18.42.39',\n",
       " '2004.02.14.18.52.39',\n",
       " '2004.02.14.19.02.39',\n",
       " '2004.02.14.19.12.39',\n",
       " '2004.02.14.19.22.39',\n",
       " '2004.02.14.19.32.39',\n",
       " '2004.02.14.19.42.39',\n",
       " '2004.02.14.19.52.39',\n",
       " '2004.02.14.20.02.39',\n",
       " '2004.02.14.20.12.39',\n",
       " '2004.02.14.20.22.39',\n",
       " '2004.02.14.20.32.39',\n",
       " '2004.02.14.20.42.39',\n",
       " '2004.02.14.20.52.39',\n",
       " '2004.02.14.21.02.39',\n",
       " '2004.02.14.21.12.39',\n",
       " '2004.02.14.21.22.39',\n",
       " '2004.02.14.21.32.39',\n",
       " '2004.02.14.21.42.39',\n",
       " '2004.02.14.21.52.39',\n",
       " '2004.02.14.22.02.39',\n",
       " '2004.02.14.22.12.39',\n",
       " '2004.02.14.22.22.39',\n",
       " '2004.02.14.22.32.39',\n",
       " '2004.02.14.22.42.39',\n",
       " '2004.02.14.22.52.39',\n",
       " '2004.02.14.23.02.39',\n",
       " '2004.02.14.23.12.39',\n",
       " '2004.02.14.23.22.39',\n",
       " '2004.02.14.23.32.39',\n",
       " '2004.02.14.23.42.39',\n",
       " '2004.02.14.23.52.39',\n",
       " '2004.02.15.00.02.39',\n",
       " '2004.02.15.00.12.39',\n",
       " '2004.02.15.00.22.39',\n",
       " '2004.02.15.00.32.39',\n",
       " '2004.02.15.00.42.39',\n",
       " '2004.02.15.00.52.39',\n",
       " '2004.02.15.01.02.39',\n",
       " '2004.02.15.01.12.39',\n",
       " '2004.02.15.01.22.39',\n",
       " '2004.02.15.01.32.39',\n",
       " '2004.02.15.01.42.39',\n",
       " '2004.02.15.01.52.39',\n",
       " '2004.02.15.02.02.39',\n",
       " '2004.02.15.02.12.39',\n",
       " '2004.02.15.02.22.39',\n",
       " '2004.02.15.02.32.39',\n",
       " '2004.02.15.02.42.39',\n",
       " '2004.02.15.02.52.39',\n",
       " '2004.02.15.03.02.39',\n",
       " '2004.02.15.03.12.39',\n",
       " '2004.02.15.03.22.39',\n",
       " '2004.02.15.03.32.39',\n",
       " '2004.02.15.03.42.39',\n",
       " '2004.02.15.03.52.39',\n",
       " '2004.02.15.04.02.39',\n",
       " '2004.02.15.04.12.39',\n",
       " '2004.02.15.04.22.39',\n",
       " '2004.02.15.04.32.39',\n",
       " '2004.02.15.04.42.39',\n",
       " '2004.02.15.04.52.39',\n",
       " '2004.02.15.05.02.39',\n",
       " '2004.02.15.05.12.39',\n",
       " '2004.02.15.05.22.39',\n",
       " '2004.02.15.05.32.39',\n",
       " '2004.02.15.05.42.39',\n",
       " '2004.02.15.05.52.39',\n",
       " '2004.02.15.06.02.39',\n",
       " '2004.02.15.06.12.39',\n",
       " '2004.02.15.06.22.39',\n",
       " '2004.02.15.06.32.39',\n",
       " '2004.02.15.06.42.39',\n",
       " '2004.02.15.06.52.39',\n",
       " '2004.02.15.07.02.39',\n",
       " '2004.02.15.07.12.39',\n",
       " '2004.02.15.07.22.39',\n",
       " '2004.02.15.07.32.39',\n",
       " '2004.02.15.07.42.39',\n",
       " '2004.02.15.07.52.39',\n",
       " '2004.02.15.08.02.39',\n",
       " '2004.02.15.08.12.39',\n",
       " '2004.02.15.08.22.39',\n",
       " '2004.02.15.08.32.39',\n",
       " '2004.02.15.08.42.39',\n",
       " '2004.02.15.08.52.39',\n",
       " '2004.02.15.09.02.39',\n",
       " '2004.02.15.09.12.39',\n",
       " '2004.02.15.09.22.39',\n",
       " '2004.02.15.09.32.39',\n",
       " '2004.02.15.09.42.39',\n",
       " '2004.02.15.09.52.39',\n",
       " '2004.02.15.10.02.39',\n",
       " '2004.02.15.10.12.39',\n",
       " '2004.02.15.10.22.39',\n",
       " '2004.02.15.10.32.39',\n",
       " '2004.02.15.10.42.39',\n",
       " '2004.02.15.10.52.39',\n",
       " '2004.02.15.11.02.39',\n",
       " '2004.02.15.11.12.39',\n",
       " '2004.02.15.11.22.39',\n",
       " '2004.02.15.11.32.39',\n",
       " '2004.02.15.11.42.39',\n",
       " '2004.02.15.11.52.39',\n",
       " '2004.02.15.12.02.39',\n",
       " '2004.02.15.12.12.39',\n",
       " '2004.02.15.12.22.39',\n",
       " '2004.02.15.12.32.39',\n",
       " '2004.02.15.12.42.39',\n",
       " '2004.02.15.12.52.39',\n",
       " '2004.02.15.13.02.39',\n",
       " '2004.02.15.13.12.39',\n",
       " '2004.02.15.13.22.39',\n",
       " '2004.02.15.13.32.39',\n",
       " '2004.02.15.13.42.39',\n",
       " '2004.02.15.13.52.39',\n",
       " '2004.02.15.14.02.39',\n",
       " '2004.02.15.14.12.39',\n",
       " '2004.02.15.14.22.39',\n",
       " '2004.02.15.14.32.39',\n",
       " '2004.02.15.14.42.39',\n",
       " '2004.02.15.14.52.39',\n",
       " '2004.02.15.15.02.39',\n",
       " '2004.02.15.15.12.39',\n",
       " '2004.02.15.15.22.39',\n",
       " '2004.02.15.15.32.39',\n",
       " '2004.02.15.15.42.39',\n",
       " '2004.02.15.15.52.39',\n",
       " '2004.02.15.16.02.39',\n",
       " '2004.02.15.16.12.39',\n",
       " '2004.02.15.16.22.39',\n",
       " '2004.02.15.16.32.39',\n",
       " '2004.02.15.16.42.39',\n",
       " '2004.02.15.16.52.39',\n",
       " '2004.02.15.17.02.39',\n",
       " '2004.02.15.17.12.39',\n",
       " '2004.02.15.17.22.39',\n",
       " '2004.02.15.17.32.39',\n",
       " '2004.02.15.17.42.39',\n",
       " '2004.02.15.17.52.39',\n",
       " '2004.02.15.18.02.39',\n",
       " '2004.02.15.18.12.39',\n",
       " '2004.02.15.18.22.39',\n",
       " '2004.02.15.18.32.39',\n",
       " '2004.02.15.18.42.39',\n",
       " '2004.02.15.18.52.39',\n",
       " '2004.02.15.19.02.39',\n",
       " '2004.02.15.19.12.39',\n",
       " '2004.02.15.19.22.39',\n",
       " '2004.02.15.19.32.39',\n",
       " '2004.02.15.19.42.39',\n",
       " '2004.02.15.19.52.39',\n",
       " '2004.02.15.20.02.39',\n",
       " '2004.02.15.20.12.39',\n",
       " '2004.02.15.20.22.39',\n",
       " '2004.02.15.20.32.39',\n",
       " '2004.02.15.20.42.39',\n",
       " '2004.02.15.20.52.39',\n",
       " '2004.02.15.21.02.39',\n",
       " '2004.02.15.21.12.39',\n",
       " '2004.02.15.21.22.39',\n",
       " '2004.02.15.21.32.39',\n",
       " '2004.02.15.21.42.39',\n",
       " '2004.02.15.21.52.39',\n",
       " '2004.02.15.22.02.39',\n",
       " '2004.02.15.22.12.39',\n",
       " '2004.02.15.22.22.39',\n",
       " '2004.02.15.22.32.39',\n",
       " '2004.02.15.22.42.39',\n",
       " '2004.02.15.22.52.39',\n",
       " '2004.02.15.23.02.39',\n",
       " '2004.02.15.23.12.39',\n",
       " '2004.02.15.23.22.39',\n",
       " '2004.02.15.23.32.39',\n",
       " '2004.02.15.23.42.39',\n",
       " '2004.02.15.23.52.39',\n",
       " '2004.02.16.00.02.39',\n",
       " '2004.02.16.00.12.39',\n",
       " '2004.02.16.00.22.39',\n",
       " '2004.02.16.00.32.39',\n",
       " '2004.02.16.00.42.39',\n",
       " '2004.02.16.00.52.39',\n",
       " '2004.02.16.01.02.39',\n",
       " '2004.02.16.01.12.39',\n",
       " '2004.02.16.01.22.39',\n",
       " '2004.02.16.01.32.39',\n",
       " '2004.02.16.01.42.39',\n",
       " '2004.02.16.01.52.39',\n",
       " '2004.02.16.02.02.39',\n",
       " '2004.02.16.02.12.39',\n",
       " '2004.02.16.02.22.39',\n",
       " '2004.02.16.02.32.39',\n",
       " '2004.02.16.02.42.39',\n",
       " '2004.02.16.02.52.39',\n",
       " '2004.02.16.03.02.39',\n",
       " '2004.02.16.03.12.39',\n",
       " '2004.02.16.03.22.39',\n",
       " '2004.02.16.03.32.39',\n",
       " '2004.02.16.03.42.39',\n",
       " '2004.02.16.03.52.39',\n",
       " '2004.02.16.04.02.39',\n",
       " '2004.02.16.04.12.39',\n",
       " '2004.02.16.04.22.39',\n",
       " '2004.02.16.04.32.39',\n",
       " '2004.02.16.04.42.39',\n",
       " '2004.02.16.04.52.39',\n",
       " '2004.02.16.05.02.39',\n",
       " '2004.02.16.05.12.39',\n",
       " '2004.02.16.05.22.39',\n",
       " '2004.02.16.05.32.39',\n",
       " '2004.02.16.05.42.39',\n",
       " '2004.02.16.05.52.39',\n",
       " '2004.02.16.06.02.39',\n",
       " '2004.02.16.06.12.39',\n",
       " '2004.02.16.06.22.39',\n",
       " '2004.02.16.06.32.39',\n",
       " '2004.02.16.06.42.39',\n",
       " '2004.02.16.06.52.39',\n",
       " '2004.02.16.07.02.39',\n",
       " '2004.02.16.07.12.39',\n",
       " '2004.02.16.07.22.39',\n",
       " '2004.02.16.07.32.39',\n",
       " '2004.02.16.07.42.39',\n",
       " '2004.02.16.07.52.39',\n",
       " '2004.02.16.08.02.39',\n",
       " '2004.02.16.08.12.39',\n",
       " '2004.02.16.08.22.39',\n",
       " '2004.02.16.08.32.39',\n",
       " '2004.02.16.08.42.39',\n",
       " '2004.02.16.08.52.39',\n",
       " '2004.02.16.09.02.39',\n",
       " '2004.02.16.09.12.39',\n",
       " '2004.02.16.09.22.39',\n",
       " '2004.02.16.09.32.39',\n",
       " '2004.02.16.09.42.39',\n",
       " '2004.02.16.09.52.39',\n",
       " '2004.02.16.10.02.39',\n",
       " '2004.02.16.10.12.39',\n",
       " '2004.02.16.10.22.39',\n",
       " '2004.02.16.10.32.39',\n",
       " '2004.02.16.10.42.39',\n",
       " '2004.02.16.10.52.39',\n",
       " '2004.02.16.11.02.39',\n",
       " '2004.02.16.11.12.39',\n",
       " '2004.02.16.11.22.39',\n",
       " '2004.02.16.11.32.39',\n",
       " '2004.02.16.11.42.39',\n",
       " '2004.02.16.11.52.39',\n",
       " '2004.02.16.12.02.39',\n",
       " '2004.02.16.12.12.39',\n",
       " '2004.02.16.12.22.39',\n",
       " '2004.02.16.12.32.39',\n",
       " '2004.02.16.12.42.39',\n",
       " '2004.02.16.12.52.39',\n",
       " '2004.02.16.13.02.39',\n",
       " '2004.02.16.13.12.39',\n",
       " '2004.02.16.13.22.39',\n",
       " '2004.02.16.13.32.39',\n",
       " '2004.02.16.13.42.39',\n",
       " '2004.02.16.13.52.39',\n",
       " '2004.02.16.14.02.39',\n",
       " '2004.02.16.14.12.39',\n",
       " '2004.02.16.14.22.39',\n",
       " '2004.02.16.14.32.39',\n",
       " '2004.02.16.14.42.39',\n",
       " '2004.02.16.14.52.39',\n",
       " '2004.02.16.15.02.39',\n",
       " '2004.02.16.15.12.39',\n",
       " '2004.02.16.15.22.39',\n",
       " '2004.02.16.15.32.39',\n",
       " '2004.02.16.15.42.39',\n",
       " '2004.02.16.15.52.39',\n",
       " '2004.02.16.16.02.39',\n",
       " '2004.02.16.16.12.39',\n",
       " '2004.02.16.16.22.39',\n",
       " '2004.02.16.16.32.39',\n",
       " '2004.02.16.16.42.39',\n",
       " '2004.02.16.16.52.39',\n",
       " '2004.02.16.17.02.39',\n",
       " '2004.02.16.17.12.39',\n",
       " '2004.02.16.17.22.39',\n",
       " '2004.02.16.17.32.39',\n",
       " '2004.02.16.17.42.39',\n",
       " '2004.02.16.17.52.39',\n",
       " '2004.02.16.18.02.39',\n",
       " '2004.02.16.18.12.39',\n",
       " '2004.02.16.18.22.39',\n",
       " '2004.02.16.18.32.39',\n",
       " '2004.02.16.18.42.39',\n",
       " '2004.02.16.18.52.39',\n",
       " '2004.02.16.19.02.39',\n",
       " '2004.02.16.19.12.39',\n",
       " '2004.02.16.19.22.39',\n",
       " '2004.02.16.19.32.39',\n",
       " '2004.02.16.19.42.39',\n",
       " '2004.02.16.19.52.39',\n",
       " '2004.02.16.20.02.39',\n",
       " '2004.02.16.20.12.39',\n",
       " '2004.02.16.20.22.39',\n",
       " '2004.02.16.20.32.39',\n",
       " '2004.02.16.20.42.39',\n",
       " '2004.02.16.20.52.39',\n",
       " '2004.02.16.21.02.39',\n",
       " '2004.02.16.21.12.39',\n",
       " '2004.02.16.21.22.39',\n",
       " '2004.02.16.21.32.39',\n",
       " '2004.02.16.21.42.39',\n",
       " '2004.02.16.21.52.39',\n",
       " '2004.02.16.22.02.39',\n",
       " '2004.02.16.22.12.39',\n",
       " '2004.02.16.22.22.39',\n",
       " '2004.02.16.22.32.39',\n",
       " '2004.02.16.22.42.39',\n",
       " '2004.02.16.22.52.39',\n",
       " '2004.02.16.23.02.39',\n",
       " '2004.02.16.23.12.39',\n",
       " '2004.02.16.23.22.39',\n",
       " '2004.02.16.23.32.39',\n",
       " '2004.02.16.23.42.39',\n",
       " '2004.02.16.23.52.39',\n",
       " '2004.02.17.00.02.39',\n",
       " '2004.02.17.00.12.39',\n",
       " '2004.02.17.00.22.39',\n",
       " '2004.02.17.00.32.39',\n",
       " '2004.02.17.00.42.39',\n",
       " '2004.02.17.00.52.39',\n",
       " '2004.02.17.01.02.39',\n",
       " '2004.02.17.01.12.39',\n",
       " '2004.02.17.01.22.39',\n",
       " '2004.02.17.01.32.39',\n",
       " '2004.02.17.01.42.39',\n",
       " '2004.02.17.01.52.39',\n",
       " '2004.02.17.02.02.39',\n",
       " '2004.02.17.02.12.39',\n",
       " '2004.02.17.02.22.39',\n",
       " '2004.02.17.02.32.39',\n",
       " '2004.02.17.02.42.39',\n",
       " '2004.02.17.02.52.39',\n",
       " '2004.02.17.03.02.39',\n",
       " '2004.02.17.03.12.39',\n",
       " '2004.02.17.03.22.39',\n",
       " '2004.02.17.03.32.39',\n",
       " '2004.02.17.03.42.39',\n",
       " '2004.02.17.03.52.39',\n",
       " '2004.02.17.04.02.39',\n",
       " '2004.02.17.04.12.39',\n",
       " '2004.02.17.04.22.39',\n",
       " '2004.02.17.04.32.39',\n",
       " '2004.02.17.04.42.39',\n",
       " '2004.02.17.04.52.39',\n",
       " '2004.02.17.05.02.39',\n",
       " '2004.02.17.05.12.39',\n",
       " '2004.02.17.05.22.39',\n",
       " '2004.02.17.05.32.39',\n",
       " '2004.02.17.05.42.39',\n",
       " '2004.02.17.05.52.39',\n",
       " '2004.02.17.06.02.39',\n",
       " '2004.02.17.06.12.39',\n",
       " '2004.02.17.06.22.39',\n",
       " '2004.02.17.06.32.39',\n",
       " '2004.02.17.06.42.39',\n",
       " '2004.02.17.06.52.39',\n",
       " '2004.02.17.07.02.39',\n",
       " '2004.02.17.07.12.39',\n",
       " '2004.02.17.07.22.39',\n",
       " '2004.02.17.07.32.39',\n",
       " '2004.02.17.07.42.39',\n",
       " '2004.02.17.07.52.39',\n",
       " '2004.02.17.08.02.39',\n",
       " '2004.02.17.08.12.39',\n",
       " '2004.02.17.08.22.39',\n",
       " '2004.02.17.08.32.39',\n",
       " '2004.02.17.08.42.39',\n",
       " '2004.02.17.08.52.39',\n",
       " '2004.02.17.09.02.39',\n",
       " '2004.02.17.09.12.39',\n",
       " '2004.02.17.09.22.39',\n",
       " '2004.02.17.09.32.39',\n",
       " '2004.02.17.09.42.39',\n",
       " '2004.02.17.09.52.39',\n",
       " '2004.02.17.10.02.39',\n",
       " '2004.02.17.10.12.39',\n",
       " '2004.02.17.10.22.39',\n",
       " '2004.02.17.10.32.39',\n",
       " '2004.02.17.10.42.39',\n",
       " '2004.02.17.10.52.39',\n",
       " '2004.02.17.11.02.39',\n",
       " '2004.02.17.11.12.39',\n",
       " '2004.02.17.11.22.39',\n",
       " '2004.02.17.11.32.39',\n",
       " '2004.02.17.11.42.39',\n",
       " '2004.02.17.11.52.39',\n",
       " '2004.02.17.12.02.39',\n",
       " '2004.02.17.12.12.39',\n",
       " '2004.02.17.12.22.39',\n",
       " '2004.02.17.12.32.39',\n",
       " '2004.02.17.12.42.39',\n",
       " '2004.02.17.12.52.39',\n",
       " '2004.02.17.13.02.39',\n",
       " '2004.02.17.13.12.39',\n",
       " '2004.02.17.13.22.39',\n",
       " '2004.02.17.13.32.39',\n",
       " '2004.02.17.13.42.39',\n",
       " '2004.02.17.13.52.39',\n",
       " '2004.02.17.14.02.39',\n",
       " '2004.02.17.14.12.39',\n",
       " '2004.02.17.14.22.39',\n",
       " '2004.02.17.14.32.39',\n",
       " '2004.02.17.14.42.39',\n",
       " '2004.02.17.14.52.39',\n",
       " '2004.02.17.15.02.39',\n",
       " '2004.02.17.15.12.39',\n",
       " '2004.02.17.15.22.39',\n",
       " '2004.02.17.15.32.39',\n",
       " '2004.02.17.15.42.39',\n",
       " '2004.02.17.15.52.39',\n",
       " '2004.02.17.16.02.39',\n",
       " '2004.02.17.16.12.39',\n",
       " '2004.02.17.16.22.39',\n",
       " '2004.02.17.16.32.39',\n",
       " '2004.02.17.16.42.39',\n",
       " '2004.02.17.16.52.39',\n",
       " '2004.02.17.17.02.39',\n",
       " '2004.02.17.17.12.39',\n",
       " '2004.02.17.17.22.39',\n",
       " '2004.02.17.17.32.39',\n",
       " '2004.02.17.17.42.39',\n",
       " '2004.02.17.17.52.39',\n",
       " '2004.02.17.18.02.39',\n",
       " '2004.02.17.18.12.39',\n",
       " '2004.02.17.18.22.39',\n",
       " '2004.02.17.18.32.39',\n",
       " '2004.02.17.18.42.39',\n",
       " '2004.02.17.18.52.39',\n",
       " '2004.02.17.19.02.39',\n",
       " '2004.02.17.19.12.39',\n",
       " '2004.02.17.19.22.39',\n",
       " '2004.02.17.19.32.39',\n",
       " '2004.02.17.19.42.39',\n",
       " '2004.02.17.19.52.39',\n",
       " '2004.02.17.20.02.39',\n",
       " '2004.02.17.20.12.39',\n",
       " '2004.02.17.20.22.39',\n",
       " '2004.02.17.20.32.39',\n",
       " '2004.02.17.20.42.39',\n",
       " '2004.02.17.20.52.39',\n",
       " '2004.02.17.21.02.39',\n",
       " '2004.02.17.21.12.39',\n",
       " '2004.02.17.21.22.39',\n",
       " '2004.02.17.21.32.39',\n",
       " '2004.02.17.21.42.39',\n",
       " '2004.02.17.21.52.39',\n",
       " '2004.02.17.22.02.39',\n",
       " '2004.02.17.22.12.39',\n",
       " '2004.02.17.22.22.39',\n",
       " '2004.02.17.22.32.39',\n",
       " '2004.02.17.22.42.39',\n",
       " '2004.02.17.22.52.39',\n",
       " '2004.02.17.23.02.39',\n",
       " '2004.02.17.23.12.39',\n",
       " '2004.02.17.23.22.39',\n",
       " '2004.02.17.23.32.39',\n",
       " '2004.02.17.23.42.39',\n",
       " '2004.02.17.23.52.39',\n",
       " '2004.02.18.00.02.39',\n",
       " '2004.02.18.00.12.39',\n",
       " '2004.02.18.00.22.39',\n",
       " '2004.02.18.00.32.39',\n",
       " '2004.02.18.00.42.39',\n",
       " '2004.02.18.00.52.39',\n",
       " '2004.02.18.01.02.39',\n",
       " '2004.02.18.01.12.39',\n",
       " '2004.02.18.01.22.39',\n",
       " '2004.02.18.01.32.39',\n",
       " '2004.02.18.01.42.39',\n",
       " '2004.02.18.01.52.39',\n",
       " '2004.02.18.02.02.39',\n",
       " '2004.02.18.02.12.39',\n",
       " '2004.02.18.02.22.39',\n",
       " '2004.02.18.02.32.39',\n",
       " '2004.02.18.02.42.39',\n",
       " '2004.02.18.02.52.39',\n",
       " '2004.02.18.03.02.39',\n",
       " '2004.02.18.03.12.39',\n",
       " '2004.02.18.03.22.39',\n",
       " '2004.02.18.03.32.39',\n",
       " '2004.02.18.03.42.39',\n",
       " '2004.02.18.03.52.39',\n",
       " '2004.02.18.04.02.39',\n",
       " '2004.02.18.04.12.39',\n",
       " '2004.02.18.04.22.39',\n",
       " '2004.02.18.04.32.39',\n",
       " '2004.02.18.04.42.39',\n",
       " '2004.02.18.04.52.39',\n",
       " '2004.02.18.05.02.39',\n",
       " '2004.02.18.05.12.39',\n",
       " '2004.02.18.05.22.39',\n",
       " '2004.02.18.05.32.39',\n",
       " '2004.02.18.05.42.39',\n",
       " '2004.02.18.05.52.39',\n",
       " '2004.02.18.06.02.39',\n",
       " '2004.02.18.06.12.39',\n",
       " '2004.02.18.06.22.39',\n",
       " '2004.02.18.06.32.39',\n",
       " '2004.02.18.06.42.39',\n",
       " '2004.02.18.06.52.39',\n",
       " '2004.02.18.07.02.39',\n",
       " '2004.02.18.07.12.39',\n",
       " '2004.02.18.07.22.39',\n",
       " '2004.02.18.07.32.39',\n",
       " '2004.02.18.07.42.39',\n",
       " '2004.02.18.07.52.39',\n",
       " '2004.02.18.08.02.39',\n",
       " '2004.02.18.08.12.39',\n",
       " '2004.02.18.08.22.39',\n",
       " '2004.02.18.08.32.39',\n",
       " '2004.02.18.08.42.39',\n",
       " '2004.02.18.08.52.39',\n",
       " '2004.02.18.09.02.39',\n",
       " '2004.02.18.09.12.39',\n",
       " '2004.02.18.09.22.39',\n",
       " '2004.02.18.09.32.39',\n",
       " '2004.02.18.09.42.39',\n",
       " '2004.02.18.09.52.39',\n",
       " '2004.02.18.10.02.39',\n",
       " '2004.02.18.10.12.39',\n",
       " '2004.02.18.10.22.39',\n",
       " '2004.02.18.10.32.39',\n",
       " '2004.02.18.10.42.39',\n",
       " '2004.02.18.10.52.39',\n",
       " '2004.02.18.11.02.39',\n",
       " '2004.02.18.11.12.39',\n",
       " '2004.02.18.11.22.39',\n",
       " '2004.02.18.11.32.39',\n",
       " '2004.02.18.11.42.39',\n",
       " '2004.02.18.11.52.39',\n",
       " '2004.02.18.12.02.39',\n",
       " '2004.02.18.12.12.39',\n",
       " '2004.02.18.12.22.39',\n",
       " '2004.02.18.12.32.39',\n",
       " '2004.02.18.12.42.39',\n",
       " '2004.02.18.12.52.39',\n",
       " '2004.02.18.13.02.39',\n",
       " '2004.02.18.13.12.39',\n",
       " '2004.02.18.13.22.39',\n",
       " '2004.02.18.13.32.39',\n",
       " '2004.02.18.13.42.39',\n",
       " '2004.02.18.13.52.39',\n",
       " '2004.02.18.14.02.39',\n",
       " '2004.02.18.14.12.39',\n",
       " '2004.02.18.14.22.39',\n",
       " '2004.02.18.14.32.39',\n",
       " '2004.02.18.14.42.39',\n",
       " '2004.02.18.14.52.39',\n",
       " '2004.02.18.15.02.39',\n",
       " '2004.02.18.15.12.39',\n",
       " '2004.02.18.15.22.39',\n",
       " '2004.02.18.15.32.39',\n",
       " '2004.02.18.15.42.39',\n",
       " '2004.02.18.15.52.39',\n",
       " '2004.02.18.16.02.39',\n",
       " '2004.02.18.16.12.39',\n",
       " '2004.02.18.16.22.39',\n",
       " '2004.02.18.16.32.39',\n",
       " '2004.02.18.16.42.39',\n",
       " '2004.02.18.16.52.39',\n",
       " '2004.02.18.17.02.39',\n",
       " '2004.02.18.17.12.39',\n",
       " '2004.02.18.17.22.39',\n",
       " '2004.02.18.17.32.39',\n",
       " '2004.02.18.17.42.39',\n",
       " '2004.02.18.17.52.39',\n",
       " '2004.02.18.18.02.39',\n",
       " '2004.02.18.18.12.39',\n",
       " '2004.02.18.18.22.39',\n",
       " '2004.02.18.18.32.39',\n",
       " '2004.02.18.18.42.39',\n",
       " '2004.02.18.18.52.39',\n",
       " '2004.02.18.19.02.39',\n",
       " '2004.02.18.19.12.39',\n",
       " '2004.02.18.19.22.39',\n",
       " '2004.02.18.19.32.39',\n",
       " '2004.02.18.19.42.39',\n",
       " '2004.02.18.19.52.39',\n",
       " '2004.02.18.20.02.39',\n",
       " '2004.02.18.20.12.39',\n",
       " '2004.02.18.20.22.39',\n",
       " '2004.02.18.20.32.39',\n",
       " '2004.02.18.20.42.39',\n",
       " '2004.02.18.20.52.39',\n",
       " '2004.02.18.21.02.39',\n",
       " '2004.02.18.21.12.39',\n",
       " '2004.02.18.21.22.39',\n",
       " '2004.02.18.21.32.39',\n",
       " '2004.02.18.21.42.39',\n",
       " '2004.02.18.21.52.39',\n",
       " '2004.02.18.22.02.39',\n",
       " '2004.02.18.22.12.39',\n",
       " '2004.02.18.22.22.39',\n",
       " '2004.02.18.22.32.39',\n",
       " '2004.02.18.22.42.39',\n",
       " '2004.02.18.22.52.39',\n",
       " '2004.02.18.23.02.39',\n",
       " '2004.02.18.23.12.39',\n",
       " '2004.02.18.23.22.39',\n",
       " '2004.02.18.23.32.39',\n",
       " '2004.02.18.23.42.39',\n",
       " '2004.02.18.23.52.39',\n",
       " '2004.02.19.00.02.39',\n",
       " '2004.02.19.00.12.39',\n",
       " '2004.02.19.00.22.39',\n",
       " '2004.02.19.00.32.39',\n",
       " '2004.02.19.00.42.39',\n",
       " '2004.02.19.00.52.39',\n",
       " '2004.02.19.01.02.39',\n",
       " '2004.02.19.01.12.39',\n",
       " '2004.02.19.01.22.39',\n",
       " '2004.02.19.01.32.39',\n",
       " '2004.02.19.01.42.39',\n",
       " '2004.02.19.01.52.39',\n",
       " '2004.02.19.02.02.39',\n",
       " '2004.02.19.02.12.39',\n",
       " '2004.02.19.02.22.39',\n",
       " '2004.02.19.02.32.39',\n",
       " '2004.02.19.02.42.39',\n",
       " '2004.02.19.02.52.39',\n",
       " '2004.02.19.03.02.39',\n",
       " '2004.02.19.03.12.39',\n",
       " '2004.02.19.03.22.39',\n",
       " '2004.02.19.03.32.39',\n",
       " '2004.02.19.03.42.39',\n",
       " '2004.02.19.03.52.39',\n",
       " '2004.02.19.04.02.39',\n",
       " '2004.02.19.04.12.39',\n",
       " '2004.02.19.04.22.39',\n",
       " '2004.02.19.04.32.39',\n",
       " '2004.02.19.04.42.39',\n",
       " '2004.02.19.04.52.39',\n",
       " '2004.02.19.05.02.39',\n",
       " '2004.02.19.05.12.39',\n",
       " '2004.02.19.05.22.39',\n",
       " '2004.02.19.05.32.39',\n",
       " '2004.02.19.05.42.39',\n",
       " '2004.02.19.05.52.39',\n",
       " '2004.02.19.06.02.39',\n",
       " '2004.02.19.06.12.39',\n",
       " '2004.02.19.06.22.39']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'E:\\\\WorkSpace\\\\data\\\\2nd_test'\n",
    "import os \n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "61e711df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path + '\\\\2004.02.12.10.32.39', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84af1844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20477</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20478</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20480 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3\n",
       "0     -0.049 -0.071 -0.132 -0.010\n",
       "1     -0.042 -0.073 -0.007 -0.105\n",
       "2      0.015  0.000  0.007  0.000\n",
       "3     -0.051  0.020 -0.002  0.100\n",
       "4     -0.107  0.010  0.127  0.054\n",
       "...      ...    ...    ...    ...\n",
       "20475  0.049 -0.051 -0.039 -0.044\n",
       "20476  0.037  0.061  0.115  0.007\n",
       "20477 -0.012  0.007  0.056 -0.007\n",
       "20478 -0.012  0.093  0.017 -0.044\n",
       "20479  0.020  0.076 -0.042 -0.029\n",
       "\n",
       "[20480 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "880cc8dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 20480 elements, new values have 1 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-5f7c5547ccb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFile\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5476\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5477\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5478\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5479\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5480\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFile\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    668\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFile\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    221\u001b[0m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 20480 elements, new values have 1 elements"
     ]
    }
   ],
   "source": [
    "data.index=[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "71dddca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "a.append(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8314ab2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.append(2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "84a45ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.append(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "79373ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20477</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20478</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20480 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3\n",
       "0     -0.049 -0.071 -0.132 -0.010\n",
       "1     -0.042 -0.073 -0.007 -0.105\n",
       "2      0.015  0.000  0.007  0.000\n",
       "3     -0.051  0.020 -0.002  0.100\n",
       "4     -0.107  0.010  0.127  0.054\n",
       "...      ...    ...    ...    ...\n",
       "20475  0.049 -0.051 -0.039 -0.044\n",
       "20476  0.037  0.061  0.115  0.007\n",
       "20477 -0.012  0.007  0.056 -0.007\n",
       "20478 -0.012  0.093  0.017 -0.044\n",
       "20479  0.020  0.076 -0.042 -0.029\n",
       "\n",
       "[20480 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4f8a68fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "89008df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "97788de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "for column in data.columns.values.tolist():\n",
    "     print(type(data[column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d48bfe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.Series([1,2,3,4])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dc4f9d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "62fc7c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape(1,4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d816349e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  2\n",
       "2  3\n",
       "3  4"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = pd.DataFrame(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "05e2a99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dc359b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('debug.txt', 'a') as f:\n",
    "    f.write(str(list(b)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f43e4081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20477</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20478</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20480 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3\n",
       "0     -0.049 -0.071 -0.132 -0.010\n",
       "1     -0.042 -0.073 -0.007 -0.105\n",
       "2      0.015  0.000  0.007  0.000\n",
       "3     -0.051  0.020 -0.002  0.100\n",
       "4     -0.107  0.010  0.127  0.054\n",
       "...      ...    ...    ...    ...\n",
       "20475  0.049 -0.051 -0.039 -0.044\n",
       "20476  0.037  0.061  0.115  0.007\n",
       "20477 -0.012  0.007  0.056 -0.007\n",
       "20478 -0.012  0.093  0.017 -0.044\n",
       "20479  0.020  0.076 -0.042 -0.029\n",
       "\n",
       "[20480 rows x 4 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b5cf8136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.049, -0.042,  0.015, ..., -0.012, -0.012,  0.02 ])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ca34e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1634202080.3096216\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1518b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-02-12 10:32:39</th>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.323551</td>\n",
       "      <td>0.487200</td>\n",
       "      <td>0.191604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 10:42:39</th>\n",
       "      <td>0.323551</td>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.456721</td>\n",
       "      <td>0.226190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 10:52:39</th>\n",
       "      <td>0.323551</td>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.456721</td>\n",
       "      <td>0.191604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 11:02:39</th>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.421504</td>\n",
       "      <td>0.226190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 11:12:39</th>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.323551</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.226190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:22:39</th>\n",
       "      <td>0.688910</td>\n",
       "      <td>0.483548</td>\n",
       "      <td>0.470881</td>\n",
       "      <td>0.470881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:32:39</th>\n",
       "      <td>0.710931</td>\n",
       "      <td>0.470881</td>\n",
       "      <td>0.470881</td>\n",
       "      <td>0.388708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:42:39</th>\n",
       "      <td>0.785562</td>\n",
       "      <td>0.619198</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.470881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:52:39</th>\n",
       "      <td>0.747841</td>\n",
       "      <td>0.510663</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.388708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 06:02:39</th>\n",
       "      <td>0.765985</td>\n",
       "      <td>0.510663</td>\n",
       "      <td>0.521124</td>\n",
       "      <td>0.510663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>982 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1         2         3\n",
       "2004-02-12 10:32:39  0.345471  0.323551  0.487200  0.191604\n",
       "2004-02-12 10:42:39  0.323551  0.345471  0.456721  0.226190\n",
       "2004-02-12 10:52:39  0.323551  0.345471  0.456721  0.191604\n",
       "2004-02-12 11:02:39  0.345471  0.345471  0.421504  0.226190\n",
       "2004-02-12 11:12:39  0.345471  0.323551  0.404762  0.226190\n",
       "...                       ...       ...       ...       ...\n",
       "2004-02-19 05:22:39  0.688910  0.483548  0.470881  0.470881\n",
       "2004-02-19 05:32:39  0.710931  0.470881  0.470881  0.388708\n",
       "2004-02-19 05:42:39  0.785562  0.619198  0.404762  0.470881\n",
       "2004-02-19 05:52:39  0.747841  0.510663  0.404762  0.388708\n",
       "2004-02-19 06:02:39  0.765985  0.510663  0.521124  0.510663\n",
       "\n",
       "[982 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "box_count_data = pd.read_csv('E:\\\\WorkSpace\\\\cache\\\\box_count_data.csv', index_col=0)\n",
    "box_count_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "456d2bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(box_count_data.iloc[:,0].unique()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25ad68f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(box_count_data.iloc[:,1].unique()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61dfc653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(box_count_data.iloc[:,2].unique()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "265f612f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(box_count_data.iloc[:,3].unique()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49a810b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34547084, 0.3235513 , 0.3235513 , 0.34547084, 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.34547084, 0.3235513 , 0.22619048,\n",
       "       0.34547084, 0.3235513 , 0.22619048, 0.3235513 , 0.34547084,\n",
       "       0.3235513 , 0.34547084, 0.3235513 , 0.3235513 , 0.22619048,\n",
       "       0.38870815, 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.22619048, 0.34547084, 0.37017545, 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.34547084, 0.3235513 , 0.3235513 ,\n",
       "       0.22619048, 0.3235513 , 0.3235513 , 0.34547084, 0.22619048,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.22619048, 0.3235513 ,\n",
       "       0.34547084, 0.3235513 , 0.3235513 , 0.3235513 , 0.34547084,\n",
       "       0.3235513 , 0.34547084, 0.3235513 , 0.22619048, 0.3235513 ,\n",
       "       0.34547084, 0.3235513 , 0.3235513 , 0.22619048, 0.3235513 ,\n",
       "       0.3235513 , 0.34547084, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.22619048, 0.34547084, 0.3235513 ,\n",
       "       0.3235513 , 0.22619048, 0.3235513 , 0.3235513 , 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.22619048, 0.3235513 , 0.34547084,\n",
       "       0.34547084, 0.34547084, 0.34547084, 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.22619048, 0.34547084, 0.3235513 , 0.3235513 ,\n",
       "       0.37017545, 0.34547084, 0.3235513 , 0.22619048, 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.34547084, 0.3235513 , 0.22619048,\n",
       "       0.34547084, 0.3235513 , 0.22619048, 0.22619048, 0.3235513 ,\n",
       "       0.34547084, 0.22619048, 0.3235513 , 0.22619048, 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.22619048, 0.3235513 , 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.22619048, 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.22619048, 0.3235513 , 0.3235513 , 0.22619048,\n",
       "       0.3235513 , 0.34547084, 0.3235513 , 0.34547084, 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.22619048, 0.34547084, 0.22619048,\n",
       "       0.34547084, 0.34547084, 0.22619048, 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.34547084, 0.3235513 , 0.3235513 , 0.22619048,\n",
       "       0.3235513 , 0.22619048, 0.38870815, 0.3235513 , 0.37017545,\n",
       "       0.22619048, 0.34547084, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.22619048, 0.34547084, 0.34547084, 0.3235513 , 0.3235513 ,\n",
       "       0.22619048, 0.3235513 , 0.3235513 , 0.34547084, 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.22619048, 0.3235513 , 0.3235513 , 0.3235513 , 0.22619048,\n",
       "       0.3235513 , 0.22619048, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.34547084, 0.22619048, 0.3235513 , 0.22619048,\n",
       "       0.34547084, 0.22619048, 0.3235513 , 0.22619048, 0.22619048,\n",
       "       0.22619048, 0.3235513 , 0.22619048, 0.3235513 , 0.22619048,\n",
       "       0.22619048, 0.3235513 , 0.3235513 , 0.22619048, 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.34547084, 0.34547084, 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.22619048, 0.3235513 , 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.22619048,\n",
       "       0.22619048, 0.3235513 , 0.22619048, 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.34547084, 0.22619048, 0.3235513 , 0.3235513 , 0.22619048,\n",
       "       0.22619048, 0.3235513 , 0.34547084, 0.22619048, 0.3235513 ,\n",
       "       0.34547084, 0.34547084, 0.3235513 , 0.34547084, 0.22619048,\n",
       "       0.3235513 , 0.3235513 , 0.22619048, 0.22619048, 0.22619048,\n",
       "       0.22619048, 0.3235513 , 0.22619048, 0.3235513 , 0.22619048,\n",
       "       0.34547084, 0.22619048, 0.3235513 , 0.3235513 , 0.22619048,\n",
       "       0.34547084, 0.3235513 , 0.3235513 , 0.22619048, 0.22619048,\n",
       "       0.22619048, 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.34547084, 0.3235513 , 0.22619048,\n",
       "       0.22619048, 0.34547084, 0.22619048, 0.3235513 , 0.34547084,\n",
       "       0.38870815, 0.34547084, 0.3235513 , 0.22619048, 0.22619048,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.37017545, 0.3235513 , 0.22619048, 0.3235513 , 0.3235513 ,\n",
       "       0.34547084, 0.3235513 , 0.22619048, 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.37017545, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.22619048, 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.34547084, 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.22619048, 0.34547084, 0.3235513 , 0.22619048,\n",
       "       0.3235513 , 0.37017545, 0.3235513 , 0.3235513 , 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.34547084, 0.3235513 , 0.3235513 ,\n",
       "       0.34547084, 0.34547084, 0.34547084, 0.3235513 , 0.22619048,\n",
       "       0.37017545, 0.34547084, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.22619048, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.22619048,\n",
       "       0.22619048, 0.3235513 , 0.22619048, 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.34547084, 0.3235513 , 0.3235513 , 0.22619048,\n",
       "       0.3235513 , 0.22619048, 0.22619048, 0.22619048, 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.34547084, 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.34547084, 0.3235513 , 0.22619048, 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.34547084, 0.3235513 ,\n",
       "       0.22619048, 0.3235513 , 0.3235513 , 0.3235513 , 0.22619048,\n",
       "       0.22619048, 0.3235513 , 0.22619048, 0.22619048, 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.22619048, 0.22619048, 0.3235513 ,\n",
       "       0.3235513 , 0.22619048, 0.22619048, 0.3235513 , 0.3235513 ,\n",
       "       0.34547084, 0.34547084, 0.22619048, 0.3235513 , 0.22619048,\n",
       "       0.3235513 , 0.34547084, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.34547084, 0.22619048, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.34547084, 0.22619048, 0.3235513 ,\n",
       "       0.34547084, 0.3235513 , 0.3235513 , 0.37017545, 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.34547084, 0.3235513 ,\n",
       "       0.34547084, 0.3235513 , 0.3235513 , 0.3235513 , 0.22619048,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.22619048, 0.3235513 ,\n",
       "       0.3235513 , 0.22619048, 0.22619048, 0.34547084, 0.3235513 ,\n",
       "       0.3235513 , 0.34547084, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.34547084,\n",
       "       0.3235513 , 0.34547084, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.34547084, 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.34547084, 0.3235513 ,\n",
       "       0.3235513 , 0.34547084, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.34547084, 0.22619048, 0.3235513 , 0.34547084, 0.22619048,\n",
       "       0.3235513 , 0.34547084, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.22619048, 0.22619048, 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.22619048, 0.3235513 , 0.22619048,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.34547084, 0.3235513 ,\n",
       "       0.34547084, 0.34547084, 0.37017545, 0.22619048, 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.34547084,\n",
       "       0.22619048, 0.34547084, 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.34547084, 0.37017545,\n",
       "       0.3235513 , 0.34547084, 0.34547084, 0.37017545, 0.34547084,\n",
       "       0.34547084, 0.3235513 , 0.34547084, 0.3235513 , 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 , 0.3235513 ,\n",
       "       0.34547084, 0.3235513 , 0.3235513 , 0.3235513 , 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.34547084, 0.3235513 , 0.34547084,\n",
       "       0.3235513 , 0.3235513 , 0.34547084, 0.3235513 , 0.38870815,\n",
       "       0.3235513 , 0.38870815, 0.37017545, 0.3235513 , 0.34547084,\n",
       "       0.34547084, 0.3235513 , 0.34547084, 0.38870815, 0.3235513 ,\n",
       "       0.34547084, 0.34547084, 0.3235513 , 0.34547084, 0.3235513 ,\n",
       "       0.34547084, 0.34547084, 0.34547084, 0.34547084, 0.34547084,\n",
       "       0.3235513 , 0.34547084, 0.38870815, 0.34547084, 0.34547084,\n",
       "       0.34547084, 0.3235513 , 0.34547084, 0.3235513 , 0.3235513 ,\n",
       "       0.34547084, 0.3235513 , 0.34547084, 0.38870815, 0.38870815,\n",
       "       0.38870815, 0.38870815, 0.34547084, 0.34547084, 0.3235513 ,\n",
       "       0.37017545, 0.38870815, 0.3235513 , 0.34547084, 0.34547084,\n",
       "       0.38870815, 0.34547084, 0.3235513 , 0.34547084, 0.34547084,\n",
       "       0.34547084, 0.3235513 , 0.3235513 , 0.38870815, 0.34547084,\n",
       "       0.34547084, 0.34547084, 0.38870815, 0.34547084, 0.3235513 ,\n",
       "       0.38870815, 0.34547084, 0.38870815, 0.34547084, 0.34547084,\n",
       "       0.34547084, 0.34547084, 0.40476191, 0.38870815, 0.38870815,\n",
       "       0.45672057, 0.40476191, 0.38870815, 0.40476191, 0.34547084,\n",
       "       0.37017545, 0.38870815, 0.34547084, 0.34547084, 0.38870815,\n",
       "       0.34547084, 0.34547084, 0.38870815, 0.40476191, 0.38870815,\n",
       "       0.3235513 , 0.38870815, 0.38870815, 0.38870815, 0.34547084,\n",
       "       0.38870815, 0.40476191, 0.38870815, 0.34547084, 0.38870815,\n",
       "       0.34547084, 0.38870815, 0.34547084, 0.38870815, 0.38870815,\n",
       "       0.34547084, 0.38870815, 0.34547084, 0.38870815, 0.38870815,\n",
       "       0.40476191, 0.38870815, 0.42150443, 0.34547084, 0.40476191,\n",
       "       0.42150443, 0.38870815, 0.38870815, 0.40476191, 0.40476191,\n",
       "       0.34547084, 0.38870815, 0.40476191, 0.40476191, 0.38870815,\n",
       "       0.38870815, 0.47088099, 0.49920472, 0.51402749, 0.55880777,\n",
       "       0.57027474, 0.49920472, 0.51066335, 0.52112426, 0.51066335,\n",
       "       0.48354791, 0.55880777, 0.52112426, 0.54918467, 0.48354791,\n",
       "       0.48354791, 0.51066335, 0.49920472, 0.52112426, 0.51066335,\n",
       "       0.51066335, 0.55880777, 0.48354791, 0.48354791, 0.52112426,\n",
       "       0.54918467, 0.51066335, 0.52112426, 0.51066335, 0.51066335,\n",
       "       0.54918467, 0.51066335, 0.51066335, 0.53872376, 0.51066335,\n",
       "       0.52112426, 0.51066335, 0.51066335, 0.47088099, 0.49920472,\n",
       "       0.51066335, 0.48354791, 0.49920472, 0.47088099, 0.45672057,\n",
       "       0.48354791, 0.47088099, 0.47088099, 0.49920472, 0.49920472,\n",
       "       0.49920472, 0.51066335, 0.47088099, 0.51402749, 0.47088099,\n",
       "       0.47088099, 0.47088099, 0.47088099, 0.40476191, 0.45672057,\n",
       "       0.4865378 , 0.38870815, 0.42150443, 0.40476191, 0.40476191,\n",
       "       0.45672057, 0.34547084, 0.38870815, 0.34547084, 0.40476191,\n",
       "       0.38870815, 0.38870815, 0.38870815, 0.38870815, 0.38870815,\n",
       "       0.38870815, 0.38870815, 0.38870815, 0.34547084, 0.34547084,\n",
       "       0.42150443, 0.34547084, 0.34547084, 0.34547084, 0.34547084,\n",
       "       0.34547084, 0.40476191, 0.34547084, 0.34547084, 0.38870815,\n",
       "       0.38870815, 0.34547084, 0.38870815, 0.38870815, 0.34547084,\n",
       "       0.38870815, 0.37017545, 0.38870815, 0.34547084, 0.38870815,\n",
       "       0.38870815, 0.34547084, 0.38870815, 0.38870815, 0.38870815,\n",
       "       0.38870815, 0.38870815, 0.47088099, 0.34547084, 0.34547084,\n",
       "       0.38870815, 0.38870815, 0.38870815, 0.40476191, 0.38870815,\n",
       "       0.38870815, 0.34547084, 0.38870815, 0.38870815, 0.34547084,\n",
       "       0.34547084, 0.38870815, 0.40476191, 0.47088099, 0.38870815,\n",
       "       0.47088099, 0.40476191, 0.40476191, 0.47088099, 0.49920472,\n",
       "       0.47088099, 0.49920472, 0.49920472, 0.48354791, 0.48354791,\n",
       "       0.51066335, 0.48354791, 0.51066335, 0.47088099, 0.51066335,\n",
       "       0.52112426, 0.51066335, 0.54918467, 0.51066335, 0.51066335,\n",
       "       0.54918467, 0.55880777, 0.54918467, 0.55880777, 0.52112426,\n",
       "       0.51066335, 0.51066335, 0.54918467, 0.48354791, 0.48354791,\n",
       "       0.51066335, 0.51066335, 0.48354791, 0.48354791, 0.51066335,\n",
       "       0.48354791, 0.51066335, 0.48354791, 0.51066335, 0.48354791,\n",
       "       0.54918467, 0.48354791, 0.47088099, 0.51066335, 0.49920472,\n",
       "       0.47088099, 0.48354791, 0.47088099, 0.52112426, 0.52112426,\n",
       "       0.49920472, 0.52548612, 0.48354791, 0.47088099, 0.52112426,\n",
       "       0.49920472, 0.48354791, 0.51066335, 0.54918467, 0.53872376,\n",
       "       0.48354791, 0.51066335, 0.52548612, 0.48354791, 0.48354791,\n",
       "       0.52112426, 0.51066335, 0.48354791, 0.48354791, 0.38870815,\n",
       "       0.34547084, 0.45672057, 0.38870815, 0.38870815, 0.34547084,\n",
       "       0.40476191, 0.40476191, 0.47088099, 0.47088099, 0.47088099,\n",
       "       0.47088099, 0.47088099, 0.52548612, 0.48354791, 0.48354791,\n",
       "       0.48354791, 0.47088099, 0.47088099, 0.51066335, 0.49920472,\n",
       "       0.51066335, 0.47088099, 0.47088099, 0.48354791, 0.51066335,\n",
       "       0.51066335, 0.49920472, 0.51066335, 0.53594703, 0.51066335,\n",
       "       0.48354791, 0.38870815, 0.38870815, 0.47088099, 0.48354791,\n",
       "       0.47088099, 0.51066335, 0.48354791, 0.54918467, 0.55880777,\n",
       "       0.60415007, 0.52112426, 0.54918467, 0.52112426, 0.40476191,\n",
       "       0.51066335, 0.47088099, 0.48354791, 0.51066335, 0.47088099,\n",
       "       0.55880777, 0.51066335, 0.40476191, 0.47088099, 0.47088099,\n",
       "       0.51066335, 0.52112426, 0.56771737, 0.48354791, 0.52112426,\n",
       "       0.51066335, 0.57027474, 0.51066335, 0.58747898, 0.52112426,\n",
       "       0.55880777, 0.55880777, 0.57918434, 0.52112426, 0.55880777,\n",
       "       0.56771737, 0.56771737, 0.5952381 , 0.57918434, 0.64451149,\n",
       "       0.64258057, 0.72060658, 0.7326639 , 0.68764965, 0.71451192,\n",
       "       0.79311257, 0.71879702, 0.68891045, 0.71093119, 0.78556247,\n",
       "       0.74784126, 0.76598523])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(box_count_data.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1aac8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('E:\\\\WorkSpace\\\\data\\\\2nd_test\\\\2004.02.12.10.32.39')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e193c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-0.049\\t-0.071\\t-0.132\\t-0.010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.042\\t-0.073\\t-0.007\\t-0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015\\t0.000\\t0.007\\t0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.051\\t0.020\\t-0.002\\t0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.107\\t0.010\\t0.127\\t0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.078\\t-0.212\\t0.042\\t-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20474</th>\n",
       "      <td>0.049\\t-0.051\\t-0.039\\t-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>0.037\\t0.061\\t0.115\\t0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>-0.012\\t0.007\\t0.056\\t-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20477</th>\n",
       "      <td>-0.012\\t0.093\\t0.017\\t-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20478</th>\n",
       "      <td>0.020\\t0.076\\t-0.042\\t-0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20479 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       -0.049\\t-0.071\\t-0.132\\t-0.010\n",
       "0      -0.042\\t-0.073\\t-0.007\\t-0.105\n",
       "1          0.015\\t0.000\\t0.007\\t0.000\n",
       "2        -0.051\\t0.020\\t-0.002\\t0.100\n",
       "3         -0.107\\t0.010\\t0.127\\t0.054\n",
       "4       -0.078\\t-0.212\\t0.042\\t-0.044\n",
       "...                               ...\n",
       "20474   0.049\\t-0.051\\t-0.039\\t-0.044\n",
       "20475      0.037\\t0.061\\t0.115\\t0.007\n",
       "20476    -0.012\\t0.007\\t0.056\\t-0.007\n",
       "20477    -0.012\\t0.093\\t0.017\\t-0.044\n",
       "20478    0.020\\t0.076\\t-0.042\\t-0.029\n",
       "\n",
       "[20479 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f6a3c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac655a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39a6efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb3c82a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.247501611709595\n"
     ]
    }
   ],
   "source": [
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ba7f693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-02-12 10:32:39</td>\n",
       "      <td>2.540276</td>\n",
       "      <td>0.437015</td>\n",
       "      <td>0.485545</td>\n",
       "      <td>1.432874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-02-12 10:42:39</td>\n",
       "      <td>2.588834</td>\n",
       "      <td>0.483075</td>\n",
       "      <td>0.528724</td>\n",
       "      <td>2.674396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-02-12 10:52:39</td>\n",
       "      <td>1.425461</td>\n",
       "      <td>0.505611</td>\n",
       "      <td>0.503669</td>\n",
       "      <td>1.414996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-02-12 11:02:39</td>\n",
       "      <td>1.474906</td>\n",
       "      <td>0.514495</td>\n",
       "      <td>0.474082</td>\n",
       "      <td>3.365529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-02-12 11:12:39</td>\n",
       "      <td>0.399725</td>\n",
       "      <td>3.518478</td>\n",
       "      <td>0.436441</td>\n",
       "      <td>1.554486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>2004-02-19 05:22:39</td>\n",
       "      <td>1.756056</td>\n",
       "      <td>2.088470</td>\n",
       "      <td>1.486476</td>\n",
       "      <td>1.876093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>2004-02-19 05:32:39</td>\n",
       "      <td>1.091837</td>\n",
       "      <td>2.084794</td>\n",
       "      <td>1.463549</td>\n",
       "      <td>2.523354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>2004-02-19 05:42:39</td>\n",
       "      <td>1.328158</td>\n",
       "      <td>2.883667</td>\n",
       "      <td>2.071426</td>\n",
       "      <td>1.619352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2004-02-19 05:52:39</td>\n",
       "      <td>1.661478</td>\n",
       "      <td>1.755205</td>\n",
       "      <td>1.565231</td>\n",
       "      <td>0.707391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>2004-02-19 06:02:39</td>\n",
       "      <td>1.813080</td>\n",
       "      <td>2.413238</td>\n",
       "      <td>1.750096</td>\n",
       "      <td>2.315270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>982 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0         1         2         3         4\n",
       "0    2004-02-12 10:32:39  2.540276  0.437015  0.485545  1.432874\n",
       "1    2004-02-12 10:42:39  2.588834  0.483075  0.528724  2.674396\n",
       "2    2004-02-12 10:52:39  1.425461  0.505611  0.503669  1.414996\n",
       "3    2004-02-12 11:02:39  1.474906  0.514495  0.474082  3.365529\n",
       "4    2004-02-12 11:12:39  0.399725  3.518478  0.436441  1.554486\n",
       "..                   ...       ...       ...       ...       ...\n",
       "977  2004-02-19 05:22:39  1.756056  2.088470  1.486476  1.876093\n",
       "978  2004-02-19 05:32:39  1.091837  2.084794  1.463549  2.523354\n",
       "979  2004-02-19 05:42:39  1.328158  2.883667  2.071426  1.619352\n",
       "980  2004-02-19 05:52:39  1.661478  1.755205  1.565231  0.707391\n",
       "981  2004-02-19 06:02:39  1.813080  2.413238  1.750096  2.315270\n",
       "\n",
       "[982 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('E:\\\\WorkSpace\\\\cache\\\\corr_dim_data.csv', index_col=0, header=None).reset_index()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "617e2108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[3].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d3b90ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-02-12 10:32:39</th>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.323551</td>\n",
       "      <td>0.487200</td>\n",
       "      <td>0.191604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 10:42:39</th>\n",
       "      <td>0.323551</td>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.456721</td>\n",
       "      <td>0.226190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 10:52:39</th>\n",
       "      <td>0.323551</td>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.456721</td>\n",
       "      <td>0.191604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 11:02:39</th>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.421504</td>\n",
       "      <td>0.226190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 11:12:39</th>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.323551</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.226190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:22:39</th>\n",
       "      <td>0.688910</td>\n",
       "      <td>0.483548</td>\n",
       "      <td>0.470881</td>\n",
       "      <td>0.470881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:32:39</th>\n",
       "      <td>0.710931</td>\n",
       "      <td>0.470881</td>\n",
       "      <td>0.470881</td>\n",
       "      <td>0.388708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:42:39</th>\n",
       "      <td>0.785562</td>\n",
       "      <td>0.619198</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.470881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:52:39</th>\n",
       "      <td>0.747841</td>\n",
       "      <td>0.510663</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.388708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 06:02:39</th>\n",
       "      <td>0.765985</td>\n",
       "      <td>0.510663</td>\n",
       "      <td>0.521124</td>\n",
       "      <td>0.510663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>982 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1         2         3\n",
       "2004-02-12 10:32:39  0.345471  0.323551  0.487200  0.191604\n",
       "2004-02-12 10:42:39  0.323551  0.345471  0.456721  0.226190\n",
       "2004-02-12 10:52:39  0.323551  0.345471  0.456721  0.191604\n",
       "2004-02-12 11:02:39  0.345471  0.345471  0.421504  0.226190\n",
       "2004-02-12 11:12:39  0.345471  0.323551  0.404762  0.226190\n",
       "...                       ...       ...       ...       ...\n",
       "2004-02-19 05:22:39  0.688910  0.483548  0.470881  0.470881\n",
       "2004-02-19 05:32:39  0.710931  0.470881  0.470881  0.388708\n",
       "2004-02-19 05:42:39  0.785562  0.619198  0.404762  0.470881\n",
       "2004-02-19 05:52:39  0.747841  0.510663  0.404762  0.388708\n",
       "2004-02-19 06:02:39  0.765985  0.510663  0.521124  0.510663\n",
       "\n",
       "[982 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_count_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2eef78b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "box_count_data.iloc[:, 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57ad2d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_dim_data = pd.read_csv('E:\\\\WorkSpace\\\\cache\\\\corr_dim_data1.csv', index_col=0, header=None).reset_index()\n",
    "corr_dim_data[4].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3570c0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABEY0lEQVR4nO2deZwVxbXHf2d29kWGnWEQAQGR1UFAFAUNior6zBPUGI2GaDQu75mEqHHXmMQYY0zk4RKjRk2MG1HcFUUQcEBWkX0bthkGmI3Zp94f9/a93X17qerue/t2T30/H5i+3bWc3k6dPnWqihhjkEgkEkm4yPBbAIlEIpF4j1TuEolEEkKkcpdIJJIQIpW7RCKRhBCp3CUSiSSEZPlVcbdu3VhhYaFf1UskEkkgWbly5SHGWL5dOt+Ue2FhIYqLi/2qXiKRSAIJEe3iSSfdMhKJRBJCpHKXSCSSECKVu0QikYQQqdwlEokkhEjlLpFIJCFEKneJRCIJIVK5SyQSSQgJtHJfvr0cW0ur/BZDIpFI0g7fBjF5wWXzlwEAdj4yw2dJJBKJJL0ItOUuaV1sLa1GfVOz32JIJIFAKndJIKg41ohpj32Oua+v81sUiSQQSOUuCQQ1DU0AgGXby1NS357Dx1By5FhK6pJIkkGgfe6irNp9BAAwpqCLz5JIREn1Sr+Tf/cZANmfIwkurcpyv+SvS3HJX5cK5fn70p3466KtSZJIIgr5LYBEEhC4lTsRZRLRN0T0jsExIqIniGgrEa0lojHeiukf9yzYgN+9v8mXuteWHMXSbYd8qVsikQQbEcv9FgAbTY6dC2BQ9N8cAE+5lCvQbC+rxvq9Fa7LufDJJbj86eUeSCSRSFobXMqdiPoCmAHgGZMkMwG8wCIsA9CZiHp5JKPn7C4/hkmPfIr9FbVJKf+sP3yO8//8ZVLKbu2k2vcukQQVXsv9cQC/ANBicrwPgD2q3yXRfRqIaA4RFRNRcVlZmYictpRW1aFw7rt4e/Ve27QvLd+FvUdrsWD1Pk9lePLTLVi4br+nZUokEokTbJU7EZ0PoJQxttIqmcG+BCOLMTafMTaOMTYuP992CUAhtpZWAwBeWbGbO4/XVuCjH27GT/+xyuNSnfPkp1vw/voDfovhKbJDVSLhgycUchKAC4noPAB5ADoS0UuMsStVaUoA9FP97gvAW7NYIsyjH24GIMP5JJLWiK3lzhj7FWOsL2OsEMAsAJ/qFDsALABwVTRq5lQAFYwx6Z+QSCQSn3A8iImIrgcAxtg8AAsBnAdgK4BjAK7xRDqJRCKROEJIuTPGFgFYFN2ep9rPANzopWCpQPpvg0PkEZNIJLyEZ4Sqg3dfqovgQSSbZImEh/Aod0mokYa7RCKGVO4SiUQSQlqlcpcf9sFDWu4SiRitUrlLggeTPSQSiRChU+4k7fJQ0iJ1u0QiROiUuyScyFBIiUQMqdwlgUCqdolEjNApd+mbDSfScJdIxAidcpeEE+mWkUjEkMpdEgikapdIxGjVyl0ag8FB3iuJRIzQKXcZChlOZF+KRCJG6JS7JJxIy10iEUMqd0kgaIlqdzkppETCh1TukkAgLXeJRAyeBbLziGgFEa0hog1EdJ9BmilEVEFEq6P/7k6OuB4hrT+JRBJyeFZiqgdwFmOsmoiyAXxJRO8xxpbp0i1mjJ3vvYh8SMMu3EjLXSIRw1a5R5fQq47+zI7+S7tXTb784UZGy0gkYnD53Ikok4hWAygF8BFjbLlBsglR1817RDTcpJw5RFRMRMVlZWXOpTZA6OVvBXoibCM6lVkhZYeqRMIHl3JnjDUzxkYB6AugiIhO0iVZBaA/Y2wkgD8DeMuknPmMsXGMsXH5+fnOpTZATgmrJWS6PXSNlUSSbISiZRhjRwEsAjBdt7+SMVYd3V4IIJuIunkkI69s/IlbgfXXEjJlGK6zkUiSD0+0TD4RdY5utwEwDcB3ujQ9KbosPREVRcst91xaC0Kmy1wTtssh769EIgZPtEwvAH8nokxElPa/GGPvENH1AMAYmwfgUgA3EFETgFoAs1iKv6Nlh5uWsFnu4WuuJJLkwhMtsxbAaIP981TbTwJ40lvRxGhpEc/jZYOQbj7hNBPHNbJPRSIRIzQjVP1+98OmTNMNeX0lEjHCo9x9fvvTzQ2SbvK4xe/7K5EEjdAod78/29NN9YRNF4bsdCSSpBMa5e73659uyjR8lrvfEqQPjc0OOpgkrY7QKHeREYzJWNAj3aJ10ksa9yhumda+GMuiTaUYdOd7WLPnqN+iSNKc0Ch3EcsuGYo43SzLdJPHLSE7Hccs2hSZtmPlriM+SyJJd0Kj3P12Q6SbMg1bB2TITseU+qZmtLQwLFizD1V1jX6LIwkwPIOYAoHIu98q3DLpJY5r0u36Joshd72PYb064tv9lThvRE/89YqxfoskCSihsdz9tlSNqvdTJr+/ZLwmZKdjybf7KwEA+yvqfJZEEmRCpNx9rt9on0cyOWkkwqYLW+Maqlan2pqug8QZoVHufluqRvV7JZOTYvy+Hl4TprP5dl8ltpVV2yeUSFwQGuXuRJd5qf8M3TIele1IUYdJGwKBPp9v91XimcXbY7/Pe2Ixpv7hcx8lkrQGQqPcfbdUDX3uSSs6KXnSmXTuUG1oasGLX+1Ek2pw0eGaBuwqrwEQUeYPvrtR2L1G0vcicUFolLuTV7/FwzkLjJSPVwpJumWczfqZKl5evgu/fnsDXvhqV2zf6b/7DGf8fpEm3Y9fKE7Iu3x7OY7UNBiWa6Ta/Q4ckASH8Cj3JHc62pVv1E54Z7k7OLeQ6QAnp1NZ14jSyuRHnGRmRl6jLaVVsX3V9U0J6T7eWKr53dLCcNn8ZbjyWaMliWWnqcQdIVLu4nlErFu7pEbK37toGfE8YbPcnTTeU36/CEUPf5IEabT07JgHAHhlxR4UPfSxpay7y4/Ftose/hhAJPTxYGUdxj34EXedUu/7w9c7D2Pp1kOafQ1NLWhoSr9PS55l9vKIaAURrSGiDUR0n0EaIqIniGgrEa0lojHJEdccu1ffrfK1Ld9wn39umXTQ7V5azU5O57CJu8NrsjLiqra0qh4DfrUw9nvDvgpN2rP/GO9IPVQdl++9dfs1vwE5j0468v15X+HyZ+JfWv/zz9UYfNd7GCvQMKcKHsu9HsBZjLGRAEYBmE5Ep+rSnAtgUPTfHABPeSkkD3aWqtptoihdEYVhV77xICaBCqzKTuPORDOWbj2Eooc/wfvr93tSXiobK9GvBKv7M+OJLzW/69PQwpM4541v9gIAquoS3XB+Y6vcWQQlKDc7+k//NM8E8EI07TIAnYmol7ei2slpd1yj3RP3eVm+thrXBNEts7rkKADgGwezF179txUY8Kt3Nfvis0ImH40hwHEd3V5q03OShrvEBVw+dyLKJKLVAEoBfMQY0/cA9QGwR/W7JLpPX84cIiomouKysjKHIhtj9xKqjyqKz8uZJI2OejaIyUkeh1UX7zwcC+m7/z/f4u631zsqp7k5IkB2hni3zqJNZQnyp7KpUj9LPNcxpV8VqatKEnC43jzGWDNjbBSAvgCKiOgkXRLDqC2DcuYzxsYxxsbl5+cLC2spY/Tv5oNVKK1K9PW2GLywXnSoNreYNxRuXvpK1YyATjoTzc6NMWZa3je7j+DSeV/hT59sAQA8t2SHJrxPhMbodcnM8Mb89EuBMkSu2d1vr8e6kgrb9E7rM4ppt55+QJr1EmuEzCrG2FEAiwBM1x0qAdBP9bsvgH1uBBNFiVk/VN2Ayb/9DIeq6zXHDbwyrl/KL7ccwsA7FqJw7rvGlr2LCmY8sTi27SQc3yzL9S+t1HT47T1ai8VbylDX2Ix/rywBAGwtTRwa39zChFYAao4GpmdneqTcU2izqp+VFsZQWlWPF77aFYtTr6xrxP6KWlV697LJ+PXw0NJibkClEtspf4koH0AjY+woEbUBMA3Ab3XJFgC4iYheBTAeQAVjzJueNE7Ul7K+qQXjHvwY/5xzKsYff1xCWsWqdWu5f7DhgOVxNwppz+G48rAqpqa+CXnZmQkWstmpfbDhYGy7qbkFkx75FABw0ajeeGt1pD3OzUps82c/vQwrdhzGzkdmcMnf1KxY7t5E27p5V7YcrEJNQzOKdx7GdZOPt69LdcEZAxZEr8uByjqsLTmKn7y4MjZj4+yifpgypLtz4SyQxnkwOePRz3Csvhkrf322r3LwvHm9AHxGRGsBfI2Iz/0dIrqeiK6PplkIYDuArQCeBvDTpEir4qAuzM7Iur1s/jIca4j0Ymssd4aEfXYYNQTHGpotj3s1AHarySRTLS0Mw+/5AL/W+cWbmltwzwJ7X/kv/r02tr14Szx2963V+zD01+/Hfm/YV4EVOw4DAPcCEk3Rk8/OJBypaUDh3Hfxoaox1POfNftQrvvaUhOfFZJQWlVnuMzc0WMNseei6KGPY/vP/uMXuOgvS/Dguxvx89fW2Mq+RBXHzMDw0MKNsd8XPrlEMxXvKyv2YM/hY5BIFPYcrkV5isJwreCJllnLGBvNGDuZMXYSY+z+6P55jLF50W3GGLuRMTaQMTaCMZY4ztpDdhyqwXjd4JT6pmbDtOXR2GGtzz2yrViXyj59TLIaIz1d1xiv06ihGPPAR54Mbvivp5Ya7q+LnvPLy3fj/fUHUNfYjKPHGvCftfuwZGu5bblKGBeAhIexVnVu6nC+6/5ufGur65uw81BN7PezX+4AEPG5bzoYGbn5THSfnsM1DfjZK9/gRyZl6zn7sS8w8y9LAETum9IBPP7hT2LPRWmVcUPxWtT1ZMWPno/LwWMArN9r/tzwwJj0oUu8J5AjVBdtKk3Yd6jKuKVULNKjtXGLsyK63dAcV2APL9yIGU98ic0Hq7CrvAallXU4oLLQNh2o0vwGtMr90+8SZQLEBtK0tDAcPWaf/l/FezD6/g9RUx+v//qXVuL+d75F0UOf4LZ/aq3TJgFfuR3Loxb8dwcqcai6PuZfnPL7RZjy6CLsUCl4AMjKtH/EFI/Smj1HUTg3HgL5/JIdePGrnQC0Sla5f/VNzXjso8044c738M7afbEY8ltf/cayvopa7ddHZV0jCue+i798tjVhvqGtpdWYPrynZXmKO8trjAYxpYErVyLA4ZoGjZ5IJYFcZk/fWQoAZSaf9He8uQ5PL96uUTrKy1jfGFd6ikX31bZy3LNgQ0I5ivWs9jmr5w8xyqPQ1NyC0Q98BALwj+tOxYi+nQAA87/YBgLhx6dH/MBPfLoFj3+8BcV3TUPvTnnYp2tMXlq2C0UDuuLXb61HfVMLKmq1DcHLy3cb1n/Cne8BAFbcMTW2r3jnYVN57dhysArTH1+MNtmZqG1sxu3nDI7dkzMfXaS5RurRmzsO1eDDDQdwjkpZ1jY04/++iE+Hq+be/3wLANiwrxKvfr0n4fjhmobYOd/0clyh2ynbHzy7HAtuOi32W2m0f//BJnyz+6gm7fl//hL9j2trWZ5bnBjt0tAPBmMe+AhFhV3xr+snpLzuQFruaotV4XCNub9Wb00qrN9XiV/8ew3qGptjLhorJQ0A/15ZEnPr8FrllXVNqKprQmVdEy548ks0NLXgYGUdHl74Xcyfe6SmAY9/HAlBPFBRh56d8jRl7Dl8DHe9tR4/fG4FcqLWsOgybIs2xccWXDrvK6G8apRh8orr5tEPN2uOqyMF1Mq9rKoec15cideK9+D5JREXzR8+3ISnFm2zrM9IsQMRl1tedqaw/GtLKnDabz/Fyl2HE/oQPt54MCH9rnJ/fOpSgQePvy1JdD2ucGFIuSGQlnttQ6Jyb2wW/17duL8SG/dXYuG6A9xhfre/tgY9OuZi8qB87k6TGt0MgYeq6zExGqWicPXzX8e2f/PexoSG4ycvrgSgVeg/eHYFV/0KXq3JecTGdaT212cZhEL+PNqR29TC8PIK468NHsprGtAmR1y5A0DJkVr811ORBu7O84Y6lsELIj53X0WQeEBdYzPui35tpgPBtNwbDOZxcOGLrK5vEprzY++RWuwqr0lQ2kbc/Oo3CfI+rIq+AICT7vlAE/2xZGs5duqsRWXRZDeoY7PdcOs/V1sef+Cd+AOeZREK+eC7GzURR6LsPVJrGJMvyiffJVrrqcbIly4VfvI4UtOAZxZv9zQefem2Q/aJUkhoLPdUDnKZ+8Y67rQrdhzGkRrtp/87a7VDAIzm/k4GZu4NUewigF5ZEa/nX8V7cMMZAz2pF9C6fH7z3kaLlPws2+7PZ7PEP37x+lp89O1BjC7ogrH9u3hS5sb9VfaJUkggLXe9tfefNfvw9c4jPkljz+ynl/ktgm8s3nLINJLICeovmnScic9LDKNl5OwynqBETDU2t2DptkP466Ktrsv8/QebXJfhJYG03I/p3Bw/e8U69K01U9C1LXb7PMimxoXrpTVj5ZaRHhvvuPzpyDyIP51yAneenYdq8N0Ba1fp4i3eTo4oSuAs9+Kdh7HGZAKnsPKnWaMc5/3dpSd7J4gA6tkQDrjw9R/XLscDafhon8tv63TI89Yukv715HCwsg7/Pe8r09HPTl3uUx5dhOtfWmWZ5rfvf+escI8InHI/coxv+PsV4wvwt2tOMTz2+GWjcNaJyZkPxEvOGJyPD249HdOG9nBchojC8hL1iMstLjo98zvkCufJy87AT063n0NGj13fR6c22bHtK8b3Fy4/TNQ3NeOWV79ByZH0nnrh2S93YMXOw7FJ8RRS0ZY2OYjg85LAKffObbPtEwGYXVSAM4d0xw1TEjvziLy7ud05lU8XTrnVzL9qLIb07IA2FrHchce1tbT6nFiYt00bLJxHj1qkkiPOLXciwqQTEid/s6JtTpbQDZ5dVIB7LxiGZ64aZ5lO3Zl73gjrUate4PeUBBXHGnHnm+sMR1h+vqkMb6/eh3sX+Bf6t6u8BkdswpHNomFSoXZFZlFNBsFT7m3ElGSOwfB3IrJUiDeeyR/dwfv+3Tx1EIDIFwUvuVkRpZ6h8nEYzY9upfw75Jlfr+nDe+LSsX0T9g/r3ZFbRkB7DXrpBl+5pUvbbDx00QihPFdPLBRaf/SK8QW4etIATBvG94X0zFXjcGJPsWvkFamcfuCPH2/GP5bvxmvFiVFWdmI0NLVg9vxlWLU7eYEOZ/x+EaY+9rllGuV6mb2n6v36qSfc4mTsjZcETrl34rSAlZtmdFMJ1i+JolR5yODU7ldPLMSO35yHjoKNk5pTCrtoRnwCkYbKSEErWLll7pwxFL07t0nYr69DBCUn73VRM3Gg1kLv26UN/jRrNHIMpiBWyO+Qq/l62vzgufjZWSdA5BRERSVqHT7y2EI0BsfslOb2Q9X4ans55r6+1jiBRxyuaYjJaQVPY9/Y4q2l7cWkgW4InnLnVI7KzTS6qXYvpnK4q0lnnjq/vqgOuVmGC1REvhbsHzEzxbr23nPw0nXjka37EiEA91wwHNedNsAwX05WBq481fxrwbA2AcW1+BdnarPGWlX+MhQuGqVdmfHqiYXI75Brqdxfv34i5qvcKTlZGbZfZnrUd2U4x1eLl249y3rshEgyVmGXyhTQZlKIfDm55V8GXxYKIraz15Z2g3TLiJGblYmlc8+yTWdtuVs/eFb66W9Xn6LZr/eLPnbZKGy4T79QVWLZZpgtS9cxLxu5WZmGw/kzMwhd25tHlZxqsGAJEHH3mH3Z8JCZQejXVTuplqu1OQi454Jh8Z9R4dTK/e0bJ2F2UYEqDQytdBHlopb5rhnDTNMprz4ROfoyCSpGZ/qcwRwqflFZax5kIeLGspo9ddXuI5oZS3mQlrsDjrNQZApWCjrD5rNaUSr6NOef3Atnntjd8sUmGCubeN32DcubP52IL35+puHxIT06JFYIa2VmVqdZDl7FNccgIkWRw4lnhwCMLuii+Q1o+036dW2L31wyQpdP/OvMLD9PPhIs3ylBaD+IInOqFM59F88sTpzdMxV9BG7W6VXLZ2W5v7lqr+kxM9LecieifkT0GRFtJKINRHSLQZopRFRBRKuj/+5OjrgReJRPzC1jZNXZuWVix02Uomq33lKN+GOtlb8dowu6oMBkmtk/zRptWJ6TAS88nUxWmDWckWPiL5zebaXIoV72T/8em/m/RWrX3E+Oe6e42LwkHfU4j2ImEI5Gw5OfNlDuqYDnXuiTKD/VrqcmA597SwvD35bsQGmV+KR7flvuPHFyTQD+lzG2iog6AFhJRB8xxvQxUIsZY+d7L2IiPC9C3C1jlNrGeraxPiPHmSatut5k+krbm4Q2WpVqVqW5Rc8no3HD6fz89BaxIp+6zMTr7V4tGjUovOmTiVE9bg3hfyzfhezMDPz3uH72iWOCOGmohbM4xoXhDrU+N4pL/2DDAc9netx7tBZd2+Y4ntGUF55l9vYzxlZFt6sAbATQxzpXcuF5oWMWpAvL3dSKo8S08UPWnXlun3l9fjMXEk+tohZ9Yn4Dd0j0r5MXLiODw0Wi25dBziJzNEVqGg9zlFc/Gf52UaXtVII731yvWTv36LEGvLPW+UpSRP7Pd2N1P+xka1Z9nhjFpa8uOepYLjOm/mERHvso+fPQCI1wIaJCAKMBLDc4PIGI1gDYB+B2xljCqhdENAfAHAAoKOCP904oRyCVkQKyezmtGga7+m3dMgbKSSS81uzz0tKdYKrFBdML4EQB6htGQ93O2ZiKqBtNnTyWe4qs0mQPYlJ3EI4u6II+urBY3mto5L6JLULvUDYRrAyJeMimNpEilzq23cjnXlppvgiQE441NKGusQVd24mPvBaFu0OViNoDeB3ArYwx/Yw5qwD0Z4yNBPBnAG8ZlcEYm88YG8cYG5efn+9QZPcvoF32eBilMWrFpVdidi+kPr2oEnTkyxYsy1UYm5uspFe05l8GZnkc1WtZg116b/Db517f2Ixrn/9aOCKECIZx5i1J7klVK2U3jaBazi82l+FT3dz+Imsg81AeXcUsFXMmcSl3IspGRLH/gzH2hv44Y6ySMVYd3V4IIJuIunkqqVYe+zSW+a1TWPvrrS09+4bDHQn12chqdcy0T4FTSKtPXqfvm51bJqEx1eVxVCdZ1xnDxApMFsmsxWhY/ie6qZl561cUpPo+8AwscoPancIXYGFSjkrOhxZuxI+eL8bG/ZUonPsuNuyrsF11TISK2kZc8OSXAMzH0HgJT7QMAXgWwEbG2GMmaXpG04GIiqLllnspqCj2rhHnDx+ZbMfLtsib4JbRKyvrAozcEkZyaNOYlUWO3FY8OFGA+sFHXCGO5K5DDdDm51IUfpvZHsCjfHneEAKhyaCsmFsmSRa8Wn5XHaoG8v1nTaQP4vcfbMJaD2egfeubvbHIIt45stzA43OfBOAHANYR0erovjsAFAAAY2wegEsB3EBETQBqAcxiybqrnCj32zhMzk6BRo6bDcixUlz2ceyCpr4+P0d4ZoJMZudhVoeLl8VNw0C6unnuXQZZd2Dz1auy3LnSpwbDvgSP3qpmgYIsz9fELSNSvhO0yt25q9IoFF1ZBEa9oLxb9lfU4p4F8W5I/UjzZGCr3BljX8Lm/jLGngTwpFdCeYFyv83XprRS0NF0HFEmemUt+pgJpzdzy1jWIdYg8MpkeG2jfx0NYiKtrIYjTw3bRrduGfPyDSpLjltGtO/FpQg806jw6mdD5Z5Ct4zVtVBsTLM0Ro1QVV18xGufzm2w96j7tYc37NV2U7oZeMVLIEeo8mBlndu9nFZWvyYBDBSQqCUubLmblWNRkKlvnQz95p7EjnsSLcPjInFvuetlMCV6qZLyXqb4Q1ev1JzWTogrcvV9UJRqss6quVnMcje7vEYzQb61Oh4a+tr1E8SFM0DvujKaRsRrwqvcxXWdKq+1Pah+mBIG1Qhqd6NBUDyyJe63qsOsLLH9POncuXR0shqUZdSh6raPQD2lcjqFQibTAaS3rK28qHbna+RzT6XlbmUFx0IeTc6vwmJeGsC7Fbf018PNzKu8tE7lbqtAI39NR3BafMaL3jN9fjsDLuFDwaYhUqexK8tuv554p5k6b7S/wqlbRvNVlFiIkVvKqCoRQ9i5x9Y/3Br6eovVeBoUvkqaDXw8yfa5a0MhzdMpYpg1Nm9+Yz1njFfuE/3UBqmYeC7Eyt3Kp+7OLeNEkTqVJbF8flns0pjV7c2D56QM0uQzKsGocXPdoWrToFilTyY8vmSn6JWvU0ubiAwbhpguS5KObxLsUDVzQ9ldR6+UcH2j9iJluZo+lY/wKnflr5HrwC6vYg3rMjPdcaM0bn3oTt0y1nm82c9Tvpt3QW+5G6dJvN6u49xtYusVkjn9gFHFVrW41Zl6y91q0JGV/iPErVK1vMkexMQbLaP0KanP9/Knl8Xmo19jE+ro1a2ub9IuVZgpfe7OsYqWsdMFtgpGtZ0wS6GdYIKy2GZXztMijegEYaLK0ugaO53yl/erSv3bS8udy+furjpueNwNThGx3K2qIvInFFLdeKzfV2G6uHncLROZO+bSp5Zi6Tb+ITiZHmn3ugTLPflPkTe9BWmIZbQM5+tppritlIFX0S/c+V0oI7eWu91LLwrPSlWJ19tbtwxfhI67+rzAtVtG73O3KC/Byk/w1xtMP5DkDlW1W+apRduwcX8lnr+mCOv3VqBTm2y0y83CsYYmLN5yCEDEch77wEeorDNuBMzw6itNv8h4Knzu4VXuFtfOrtGMTTZkGh+u9gvr3QSiPvQUaIoUuGX0EzQ5nQPHzoo2Glfg9hqKLtaRqlWYrK6he7eM/rd5iVYNARkcB+KT4SVLxevlXbSpDMU7D+PSeV8Zpl++47CwYge8dMuk3nIPr1vG6hjnHePpUHXSwanGrVuHb/qB5LhlrDo8nVnu4o1Chom1LzINrdZyDwbJdMvEYtSju/T+82ZNpIrx9AOpDIVUMFPsALBy1xFH9XhlfEmfu5dEr51ZLDZfPDPHJ7qDPG7SJ+aP/HXiIjHbz9uRb1knXxHaPJz3xW2ehDI05aWPW8a4Hm8GB1lZ4/pjVsrd6LdRHi9ZsvUQNh2ocl3OtKHdPZCGDz987qFV7sqns9UQeTOUl0qfjumOJ/5wYnknH7M6MohMro9zqWLXzlFUj97FxZfP9SAmTfSTfXq30TmGCCpDtz53vfJVu2n0ulof6qhuCN78Zi+ONUSsUvX9a4lZ/94o+bUlR9HcwnCwsg5XPLMct7y62jTtyH6dY9v3XDAMb/x0YkKa+y4cjidmj/ZENh5qpc/dO5Lrlokf0DfAbuPWReHJLjyIyYVMrvI6yB9x5biD1y2jKKpkhCgbBnUl8f23stxbbNwypZXa9UTnfb4ttn3N31agQ142+nTRLvzhhlW7j+CSvy4FAAzr1dE0XX6HXMw+pR+WqKJhRhd0wci+nXDtaQMwpGcHDO3ZESt2HsYPJxZ6Jh8Pu8prNL9ltIwLRFZD0hPvHNTlMypLsGz7EkSzm3+h6JJw7+d97qxGqDqOlhFtHOFeu2s7VHlccd6/mKIGrmufu0UETHMLw+aDVfhn8Z7YsabmFqzdW4E9h4/hU92871tLqwFE/MqfeTiTIgCUV9djR1lcMX67X79OUJwVd0wFEWHby6sAADNH9cbIvp1ARPj1+cNi6Ub07RTbfu+WydhSWo2bX/nGkXzqYAIrvt6p9fmnYuKw8Cp3h8fU8I1W9MZnnkzMF+Uwtd0d1xV3yzjI66DmDAedsIYVJ26aJ0+KV0bQLePS627lR29hDJc/HV9Js7ymASfc+V7st9kqQoeqExe2MOpstaKpuQW/ee87XDd5ACprm/C9x7/A8N5aa31MQWes2n1Us++iUb1jz/PDF4/AqQO64spT+9u+n0N7dUyIZBGB4Kz/IxVRcuFV7hbXznZWSBOfu4L6xXJrubttwJ3HtVikduAa0esmR6GQjjpUydPFOvwaxGQ81s68Jq8td41bpkV7HZ5fulOTtrymATdMGYinFm2DHSVHalFR24i2OZmxOcwPVtahbU4mOuRpF6yoa2zGib9+HwDw7Jc70CE3op427NNa66cUdsVzV5+CzzeXxXzvj8+K+887tcnGDyYU2sqm4OZ+DureAZsOuu/cTQah7VC1ejG4lQHHm+71mqji0Tbav1Zp+GUSw3zOfNF6ycH18+LrSd2HkvyvNSN4DVw3C08zA7967LdKgM82laKsynph6ME92mt+53cwX/B55H0f4qpnV4AxhpYWhvEPf4IL/vxl7LgyM6N+vdIqk1Gn+R1y0bltDsb272IpIy9Ob2f/49ri4jF9bNN5NbOkKDzL7PUjos+IaCMRbSCiWwzSEBE9QURbiWgtEY1JjrgCWCk7hyNUDV8ovV/e1p+vLcUrPWE3/4cIbldTclIn4Kxz1CxPMmeFTJlbxqIeJ5a7ugGxioD55etrbcuaOrRHbHvp3LNw5fj+AIBJJxxnmP6r7eU489FFuP21NQCAneXHAADby6ox8r4P8eqK3Xho4Uau8+jRMQ+Ad42sU7fer84dymUo5mb5Y0PzNClNAP6XMbaKiDoAWElEHzHGvlWlORfAoOi/8QCeiv71DTeWrPKcO1l4V3w+d3e4iZaJHOPbZ12+StkoI1SdhELG/lN+81nRriOO0sAtI4oTn3uzrtPU7JiZD/r0wfl45JIR6N1ZGwnTu3Mb9O4cUbiDunfAkq3Gc7fsLD8WU+oKuw9Hfr+2ssRyoFEGxRun7tGvBK/6JJ0+P9NP6omnv9humy43K9NZBS6xbVIYY/sZY6ui21UANgLQf4vMBPACi7AMQGci6uW5tAJ4ssiz6X4xZWlZh4cuBdM0omUK5nAylsCkYoe+enfXUBvnbuHnNkjvFaLX0Jnlbu6W0c99onBizw6x7Rd+VJSg2BUuHt0Hvz5/GH521gmxfQPz29nKpPjh7UaQjh8Q/yJoF/XFJ2W8gSA8j0KbHH+Uu5AziIgKAYwGsFx3qA+AParfJdF9+3X55wCYAwAFBQWCoophdc3NhqzH8pr4sY3yGK0MJEIqomWcWOI8GFmPMWvKwXk5Xezay2voW7RMEmZh2V1+DNP/9AWONTTj1OO74mBl3I/eqPPL/PL1dYZlvHXjJJRV1SM329gO7Nc1ouyzMjNw7WkDAACXjO6Dc4b3wCmFXTH2wY9N5Vuz5yj3+qQ5Bq4Nr+6Dk3I6t822TxRF35D+adYo8QodwK3ciag9gNcB3MoY0webGro9E3YwNh/AfAAYN25cUiefsHPL8FRu1gSoX0T9gBanHaJO4VJGglEXbgciqf+K5lXn45XDtWtL2C2TIsvdQpimZoY73lyHn5x+PPofp7WQG5tbUNvYjDkvFsdGjy7bfliT5vVV1isQKeRlZ6Jf17aGx9bf9z3DwTiPXTYqtj24R3tsPlhtmH/mX5bY1j9lSD4WbSrTzWej/esW0fs5u6gA91wwzD5hlKZm7c2dMiQ10x5wKXciykZEsf+DMfaGQZISAP1Uv/sC2GeQLmV48gI6eNHFI1PcumW8SaNN74FLy2EZXkxbAIhFk2hHHPP4+QUK54RXXqURWLe3Ah9vPIhv91XirRsnadLc9s/VeGftfoPccf6zxv3r2T7XXn24fb4nHH8cFm0qw9HaeCRNfLI8jzpUBYtpm5OJvGx+V4t+MexUDGAC+KJlCMCzADYyxh4zSbYAwFXRqJlTAVQwxqyfriRjZ7nz+DO5omX0ZXOk0cviJr+TOuzw4tlzWoSTfJ7GuXOkT060jEE9Fuk/3ngQQKKvvKa+yVaxq/nplIH4/ti+6N0pjzuPCG6vVftoGKFmFLTXlrtgOZsF49oTw6XF6nMKT4zOJAA/AHAWEa2O/juPiK4nouujaRYC2A5gK4CnAfw0OeKmFicLN4gPn3eHIqPl6vXCETzOpYovUSielznMZySvSDGae8b1JeT928kzi+KLX+2MTQmg0KCLbBl+zwdC9U4/qSd+//2RmH5SPP5h+vCeQmV4wbs3n4bHVe4cAOjbpY3lIuledWyLPu/69VDt0K/mlKr1AGy/qxhjX8LmkWcRzXKjV0J5gaXlbnMz7SwDq7lIRFtl14oiKW4ZZ6JoynDYQDgd2apHzC0jVn+qYjT05/Xwwu8S0tgNnR/ZtxP+eNkonPWHz43riJ6N2nVw+uB8vL/hQGyEqBusFJkS3lhU2BXDe3fC8N6dMOmEbjjloUgn7IMXnYQDFXUJ+XjWMBBB9Hk361w2IyMjTZV7UPEiXNFJzHM6hGfpSZpyt3AlOI3+IB/Gewh3qCbFLZN4vfTV6KeNBSKdp9/sPoI9R2ox+YRummOj+nWO+ePX3H0OPt9ShtqGJk1kjN4KHte/C2YX9cPUod2R50F8ttW1ap+bhcq6JtQ0NBmmNxvD4L3lLoZ+sRI7MjP0v9PE5x5UvLjvZmGOmrllEtwy1mV6vYYBl484pW4Zx1nBmFOfu9tOadWXmEU6kcFtohg9F4eqGzDzL0uwv6LW1O3W0NyCi/+6FDe/8g1ujM6GqPD3a4pi253aZuPCkb1x2SnGIcj9j4tExFx2Sj8QEXp0zEMngXA/M6wulZGSI922pcstRT73dtE4dSWE0WjVKisS3TJi8jkltJa71Qtod23N7pfx5E7ucJ0/zdwybiMZNIqWUxAvda2TUcleYPRsfbk1srjzFc8sx9u6iBiFo8caY9tLVfOYd2qTbaqctzx0LgZFZ3lUTnfWKf3QvUMuzjrR2zA9q+dAUe7azlL1/UfsYht9XXl3360L2nD/dADA4i2R6YxFV5nSu2VSsm4yQqzcvbh8PDchwbq3yaI/ntRgf6VOwfSuLNNoVsdumRTlMS2L71PIcx77aLPpse1lNRhx74dC5VWbTLoFxEeFAqrGmEgzX4xXWF1Pw85Szbb5Kr9m+Z3AW4zSGImuD6u33FNFq3TLENkfB5yFxdk9cLaNvqiVzRXRI+qWcU4qvkQS8yRmcur+4rmeqeoQM+Jv15zClY5XASX7VKyKt4qEUbaVe2sYCumBfCLlKEpadO1vvx6XECt3qytqvHaoHj7fmJjl7jXp5paJleHg1WNgjvJ56sPkuZ4eVifKmR6Pbkz682oTLZOQXB2JZprGtmgheI0fJaJI7ZbhyXvb2YOFpivwitAqdy8wX3tU5xc0OZZKrNoqy05Co/QevDWO3TIeWe5O4Wss/VTv1iy4ydg3b0ayn1erhtfwOup6VI2SKBZ/qqNlMqNzjai/injWQp04sBtW332OE9Fc0SqVu51bJpbO5LeXKzHZ1WmbniODqJrlPYdUL+qcCnxyuVty34XDudL979mDDSfYssJXt4yBqNrxZMZed69l5i0vy8Dn3tNiZO9vLhmBX04/0ZVsbghth6oVvM+G3rLgUWZuHzxhRZwEVePO506av0Iw/xsHK2tQadRT7XM/qU9HLLhpUqzet2+cZDjpVkYGIctIY1qQ7LA8q68c2w5VEyNMebZSPUJV6VBVu2UG5rc3S44xBV0wRDVlcqpplZY7L3zWPVn+tkN0YeRU4MbtoGR1Hi2j9bk6JaluoZQ3QIST+3bGSX06AQCGqRaMfudnp2nCF7MzRYVL7smId6iS5fFIGu1ft7iJljmhe3vMu3IMrprQ3xthPKRVKncvfaaJU/66Ky8ZbhlReK05w1GVLuRhAnUnCyfzCSWbxH6dOIXd2qFL25xYuiz9cEjBsr2GJypNs0933HIVMediOUJpbPSP/fSTeqFb+8Q1ZI1EbyMwm6RbWqVy54XPiNNb7oJ1pEBTiK6v6ucUCn6vi+mkL0ZhnMCCzT80sPTaZGfiN5eMsK3PbEQtgZAt2Dr62ZbaxX8TVP1cBqGQvsW5G7xQRqNtC3Xz7H995zQsu2OquIAOaZXKnd/nLl6Y6AOXnm4Z3nRGPlMXPnd4p2ySsbKRgtk9Vi+n9sBFJ2mOnTE4HyOibhUAuHNG4mIPY/p3xqVj+ybs119nvXWr3ha33P1T7zxx7laum1SHQiqNkdEYAr077P9+MDahczu/Qy46tUldSGTrVO68ysuBqkn9J7vxp6I2jWiZfOms3DJe+Lz90Dtuxg3UNsQn9spXfaZ/8fMz8fcfFaFHx0hkxcSBxyEnKwMLbpqEs4fFR4Vef8ZAky8p8/r1fRT6hSHs8NNyt+osjf0y8K8rm9595fGhuGBbDJS7aEd2Kkg/iXymQ55YAFHCi2fzqNgOUE3CaFLRj4MwuGWcwje3jHEa9ayNfbtE1ha9f+ZwFBynLFMXuRHKQKST+3bG+SdH5lEv6NoWkwflG38N6X3uareMrjHMFlQyfl5urhGqBvn8CoW0csvMODnidx/QLeKK8bnrCADfSkzPEVEpEa03OT6FiCpUC3nc7b2Y3mL2cj5yyQgsuOm0eDondygd7qpLfBuh6qEnRelk7NExV+MOscNKajv5/ufswQAi8c0n9emELQ+di6smFCbWoVFg9n02vNeSQA4s9+Q+sFbl27VDBB7r3j3coZAW0w/06JiH4rumWYZGphoeM/V5AE8CeMEizWLG2PmeSJQCzJTXrKLIdKhLtx2yTOek7GThNizMSF/x9htYLershc/bzUt87WkD0D43C7OLCnD7a2uwbm8FX508lrtJkqlDe2DnIzNiv7M5/N9WLhe7+vTHiPhGTPKWnWzsLXd1l6pxGi8Q7WMycssoKAt5pGrOditsnz7G2BcADtulCxrJslhEO1QnD8p3VZ9RNEEi9op2qipW2s2VcZPXy07Q7MwMXHlqf8uX7MKRvRP2maW+ddogjyQzd6voj3GVBdKtL+C/UlFjdU/jhoBqn64PwS5c0gt4y7Nyyyg8MPMk/HTKQEzxeA4gJ3jlc59ARGuI6D0i4hsrHQAcdagKpF38izNx9wWJURN+0KtzfBi1qH5QFjFQ40XjOVYgtNAJT8werbG0AfNzv3XaYPzsrBMA8FnkVui6DC3rFTnmJDTQz7bAyINkFi3DtC2At3CW1y43Eg01y2TBEwDo2i4Hv5h+YjAsdw5WAejPGBsJ4M8A3jJLSERziKiYiIrLyso8qNqewlhnlgNcuGUmD+pmnRBAv65tkZ2ZgevPGCheUaw+ryIG1NakWJkzR/XBjWcOjOaN7PPCClfP2zHn9OM1kSXJgojQITcL989MtFFuOmsQdj4yw/WLKxoRZLlkpEm5/LL4p4Sczuful889NysTmx88F7+cPsTT+pOFa+XOGKtkjFVHtxcCyCYiQ83GGJvPGBvHGBuXn+/OHcHLuSN6aX5fPbEQfbu0Qf9u4kq/rcHospunaj/XlQflusnHc5c791znkws1NkcWSHar+Kz01UvXjucuR13MwxePwOXjE62c7xvEcgPAhOOPMy33jvOG4umrxnHLoUbUol133/dw1YRCDFcN8zdi4c2T8d4tk9E2R2zUIZlsm6a3tNy1bgxR/DQwlfuibaC0LiuePoiR/Tq7kkPk8cjJykg715cZrpU7EfWk6NkSUVG0zHLrXMnh4tF9LI//4fsjce+Fw0FEuP2cIXjeZOED5RNQUeb/e/Zg3DptEO46P9GFMrhHB3x7//eQE/1UV+57z45xq/P4/PhItS428zqLPjfl1Q0AIl8BeheDQiZHeFxbi5Xu+0TD+vQM7xNXfrNOKUCfzm1wyZiI4iYQLh9fgFEGL15BV+OGVXQADi/XnjZAeLZEAHj35smWx4f17oihvTris9unmC6DZ4R62TU3cfVARDmrV1MCgI55Wbh6YiGXLP6GvRrs40ijbqy/+PmZePk6fuPDUA5XudMX22gZInoFwBQA3YioBMA9ALIBgDE2D8ClAG4goiYAtQBmsRQMuzxvRE8sXHcA04f3xFNXjsG2smr07dIWy7eXY19FnWGe/1JZjNmZGZgypDseuWQE5r6xTpNOscS6tMsxVZja9FkJD+GQnh3w4W2no2NetiZ2/vLx/fHKij0YkN8OXnCout702GvXTwAQcU3dcd6JeHjhd7Fjj+iGuedYKFZlgeCB+e2wrawGAPDo90fiolHxxrRf17ZYMvcsrNx1BEDcLaM0PkBE6VTWNcUiCtQ8+v2RpvXzcOu0QRjXv6vhsWG9O2Lzg+eicO67wuXeMnUQ3lq91zJNj455sQFKPNgHP+rTW7hlDDpn1977PX5Z0sByV5MY527tuilw43aN1RNO9W6r3Bljs22OP4lIqGRKuX/mSfhww0H8+PQBICKc0D0ytea7N09OUHgvXzcemw5WGZYzq6gAI/t11gwLnjmqD8qrG/ADm5nebps22PL44B6J031mZhAW3pJoEd41YygefHejsBVRo1srs0fHXBysjJz/KYURZUdEmHP6QDy88Dv06pSHK0/tHxvmfsbgfDzxyRacMSQff/pkS6ycey4YhtEFXcAYQ/eOefj4f05Hfvs8bC6tQgYBY00Uqf492VIav+4r7pyGpxZtww8nFsYammlDu+OR/zrZcOIlKx6/bBS2lVXHft9qcy+ASCN38ei+qG9qtk2rcNvZg3Hb2fZlC2ERLWOT3DqdE1Ec5BEr37wG4/nc1W4mMhTQ81BIb4tLGwI7n3u39rnY+vB5Cfu7tMtBl3Y5mn0TT+iGiSeYd3AO7aX1rWZmEH58urnP/Oapg3Dnm+vxkzPiaa6ZNADzPt8mHGescO1pA1BWVY+Lx1i7lgDg9RsmYF1JBe79z7cJ3ZbL75hmaqGuvfcc5GRmIE/VdzC2fxfDr5NrJg3Q/FYaT6XBsEN5qa+ZOABvrIpYvnnZmTFF2TEvC13a5eCZHxq7xops6rnIxgVnxKKfnymcJxkI+9y5C3bSoyqexStikTAmx01HqHrdoRpS7R5Y5e4nV4zvjyvGa636X04fgl9OH+L4E4+I8KvzhnKlHdu/q+Uivf/6yQQ0tbQk7O+Yl/xJi5SzV9wyI/p2wlNXjEmIDV5zj/myY8vvmJrSCZZSjdUIVbv0lumcyJLGU02oQyG1BzyWI6S2u1TuHpFqv53ygWDUu1E0gM+61nPJ6D7Cc+voMboO+ogls3QKIv7rICK+IAlnKhehu35gN1MCqSYO0+z3Kc49aEjlHliUT1rv+q4fu2yUZ2WF1RryAuE4d5s0bpb/S/Zdsno+7eTl6VD1grC6ZeSskAHFynL3E71bRpJIhoFyF11QxU06TR4fNZutWwZmce5eD2IKJ1K5BxSjeTnSgbBaQV6idcvw+NyT6JYRz+IZdrEH5h2q3hLWUEip3ANKRtxETkukW8YCA8vdchQqd7EO3DJpEC1jJgKZaHcZCsmHVO4BhZLgc/eCdJUrndCEQnoYLeNoLqQkqzbX87kb+txlKCQPUrkHFB5frR+E9UXxEtH5YPgX63AijJNM3mDnWiSieN+SZr/HcoTUdpfKPaDYDQDxm7C+MF6gtdw50vPGuTvQen5OHJbJ1aGafAHDapBI5R5Q0v2BlG6ZRJSvLLU7wu9G0N8pf62P884KKTFGKveAEl/EIL2UqHzx7NHOnc+RPonX1NdoGRvtnrL53EP6zErlHlDIwBeZTvhtkaYzmkFMXOltRzF5Ikuq4RrEpEQTafJ5K0dYn1Wp3ANK+g5iktEyZhjqMh7L3XNJ1GWnr1smgkG0jNeDmMKp26VyDy7p+USG9UXxkoRpbW3T2yVwI4vzvG4Rsdw1+z2WI6yPrFTuASUN1t+1JKyful4gHC0T0mtpPyskGUaFeR4KGVKLxFa5E9FzRFRKROtNjhMRPUFEW4loLRGN8V5MiZ50fSDTVKy0QtznnjRRfLbcrY8TTKYfkHPLcMFjuT8PYLrF8XMBDIr+mwPgKfdiSexId8tdkkgsFFKzEpP1EHy7Y27x86sg0y5axsQt4zVhNUhslTtj7AsAhy2SzATwAouwDEBnIkqcwFviKU6md5WkB6JumWTq37T2uZsGQ0p48MLn3gfAHtXvkug+iURigJFbxiq2KJkKzk/VadewpM5yD2cD4oVyN7oyhs8qEc0homIiKi4rK/Og6taL3QAQSfoR1yGJbhm+fN7j7whV++kHJM7xQrmXAOin+t0XwD6jhIyx+YyxcYyxcfn5+R5U3XqRD35wEV6JyS6BiyEFftoItnXLh9wVXij3BQCuikbNnAqggjG234NyJRZIn3twIZNt0/RJvNdJt9wtiufxuUucY7uGKhG9AmAKgG5EVALgHgDZAMAYmwdgIYDzAGwFcAzANckSVhJH6vbgQgbRMpbpect1KI9fxKb8NRlmnSqfe1ixVe6Msdk2xxmAGz2TSMKFfOiDh5EO8zvOPelYuIwyORbrkDhHjlANKNItE1zkCNUIducV1iiWVCGVe0CRj3044FLcIb/ZZkrcr9POzgzHBZfKPaBIyz24iM6TEtZbzRPn7ge5WZn+VOwxtj53SXoS1hc+zDi9Z2G91baRkD495HnZGXjwolE4sVcHX+r3CqncA4r0R4YDo8UoEtOE9F5zTPmrkMoVx3KzMnHR6OAPspdumYAS1ve9tcE1nztnWWm5PIqF8DxjmPzoTM7NDodaDMdZtEKkzz14GIZCtmKfu906wKn8YsnvkBvb7t+1bcrqTSZSuQeUkL7vrYJkhUIG7Zmw7VBNjRgAgHdvPi22/fhlo1NYc/KQyj2gSMs9HHiyzF5Ase9QTd1avLmZkQiZjnlZ6NQ2OyV1Jhup3ANKWF/41oZyH9PSX55k7C13sWka3KD42c89KTxLUchomYAilXtwUStynlkZA32vLVot+zVUPZbFgrzsTBTfNQ2d24TDagekcg8s0i0TPIxvGU+0jLzXqQiF7NY+1z5RgJBumYAiX/dwEPZomXa59qM9TacfINmwuUEq94CS7pZ7qjrCgoTjWSE9lyR19O7cxvSYbShkoM/cf6RyDyhprtslFmhDIXmiZYJ7s4sGdDU9lq5zy4QFqdwDSrq/8NLqEsNy+gGbvOn8jTRzVB/ceOZAw2Nylb3kwqXciWg6EW0ioq1ENNfg+BQiqiCi1dF/d3svqiRISLeMd/C24+na3o8p6GK4395yT9MTCgi2yp2IMgH8BcC5AIYBmE1EwwySLmaMjYr+u99jOSWSVkvQlVzntjmG+20X6wBQ2K0t8rIzcPs5Q5IgWbjhCYUsArCVMbYdAIjoVQAzAXybTMEkwUa6Zcxpbd80fUw6VXl87m1zsvDdA+cCAF68tgibDlR5LV5o4XHL9AGwR/W7JLpPzwQiWkNE7xHRcE+kk0gkgUc9KZca+0FM2uOTB+XjusnHeyZX2OFR7kZ3QG98rALQnzE2EsCfAbxlWBDRHCIqJqLisrIyIUElEkkwycwg/N8PxuJ3l56s2S+/7ZILj3IvAdBP9bsvgH3qBIyxSsZYdXR7IYBsIuqmL4gxNp8xNo4xNi4/P9+F2BJJcEkHpfb4ZaMwu6ggZfV9b3hP/Pe4fpp9J3RvjwtH9sbjs0alTI7WBI/P/WsAg4hoAIC9AGYBuFydgIh6AjjIGGNEVIRIo1HutbASicQckRH6F43u4/tqQ0drG/HE7HBMr5uO2Cp3xlgTEd0E4AMAmQCeY4xtIKLro8fnAbgUwA1E1ASgFsAslsp1sSSSVkw6fAnw8sglIzD3jXUAgLrGZsM0//rJBHTIk9NeuYXrCkZdLQt1++aptp8E8KS3okl46JJmc09375AHALhwVG+fJQkWrcUSmlVUgIvH9MELS3fhYpMvB6tRrRJ+ZPMYYF6/YQL6dUmvJcG6tsvBdw9MR26WHPzMgxdWd9AahtysTPz4dBn1kmykcg8wY/unp4WTl20/E6AkgpeKOeBjnSQeI80riSQNcKOXe3WKuMI6p5mLTuIv0nKXSALIjJN7obYh0iF567TBGN67E84c0t1nqSTphFTuEkkA+cvlY2LbOVkZmHFyeNb+lHiDdMtIJBJJCJHKXSLxkY7ReO4JAxMGdEskrpBuGYkkRVw3+Xh88l0pRhd0ju07rn0uFt0+xXA5uvdvnYwTe3ZMoYSSMCGVu0SSIiYMPA47H5mRsL+wWzvD9FKxS9wglbtEkmY8d/U4NDQFbWiSJN2Qyl0iSTPOOrGH3yJIQoDsUJVIJJIQIpW7RCKRhBCp3CUSiSSESOUukUgkIUQqd4lEIgkhUrlLJBJJCJHKXSKRSEKIVO4SiUQSQsivdayJqAzALofZuwE45KE4QaG1njfQes9dnnfrgue8+zPG8u0K8k25u4GIihlj4/yWI9W01vMGWu+5y/NuXXh53tItI5FIJCFEKneJRCIJIUFV7vP9FsAnWut5A6333OV5ty48O+9A+twlEolEYk1QLXeJRCKRWCCVu0QikYSQwCl3IppORJuIaCsRzfVbHi8hon5E9BkRbSSiDUR0S3R/VyL6iIi2RP92UeX5VfRabCKi7/knvTuIKJOIviGid6K/Q3/OAEBEnYno30T0XfS+T2gN505Et0Wf8fVE9AoR5YXxvInoOSIqJaL1qn3C50lEY4loXfTYE0REtpUzxgLzD0AmgG0AjgeQA2ANgGF+y+Xh+fUCMCa63QHAZgDDAPwOwNzo/rkAfhvdHha9BrkABkSvTabf5+Hw3P8HwMsA3on+Dv05R8/n7wCui27nAOgc9nMH0AfADgBtor//BeDqMJ43gNMBjAGwXrVP+DwBrAAwAQABeA/AuXZ1B81yLwKwlTG2nTHWAOBVADN9lskzGGP7GWOrottVADYi8iLMREQJIPr3ouj2TACvMsbqGWM7AGxF5BoFCiLqC2AGgGdUu0N9zgBARB0RefmfBQDGWANj7ChawbkjssRnGyLKAtAWwD6E8LwZY18AOKzbLXSeRNQLQEfG2FcsoulfUOUxJWjKvQ+AParfJdF9oYOICgGMBrAcQA/G2H4g0gAA6B5NFpbr8TiAXwBoUe0L+zkDkS/QMgB/i7qkniGidgj5uTPG9gJ4FMBuAPsBVDDGPkTIz1uF6Hn2iW7r91sSNOVu5GcKXSwnEbUH8DqAWxljlVZJDfYF6noQ0fkAShljK3mzGOwL1DmryELkk/0pxthoADWIfKabEYpzj/qYZyLieugNoB0RXWmVxWBf4M6bA7PzdHT+QVPuJQD6qX73ReRzLjQQUTYiiv0fjLE3orsPRj/NEP1bGt0fhusxCcCFRLQTETfbWUT0EsJ9zgolAEoYY8ujv/+NiLIP+7lPA7CDMVbGGGsE8AaAiQj/eSuInmdJdFu/35KgKfevAQwiogFElANgFoAFPsvkGdEe8GcBbGSMPaY6tADAD6PbPwTwtmr/LCLKJaIBAAYh0vESGBhjv2KM9WWMFSJyPz9ljF2JEJ+zAmPsAIA9RDQkumsqgG8R/nPfDeBUImobfeanItK/FPbzVhA6z6jrpoqITo1er6tUeczxuzfZQe/zeYhEkWwDcKff8nh8bqch8rm1FsDq6L/zABwH4BMAW6J/u6ry3Bm9FpvA0YOezv8ATEE8Wqa1nPMoAMXRe/4WgC6t4dwB3AfgOwDrAbyISIRI6M4bwCuI9Cs0ImKBX+vkPAGMi16rbQCeRHR2Aat/cvoBiUQiCSFBc8tIJBKJhAOp3CUSiSSESOUukUgkIUQqd4lEIgkhUrlLJBJJCJHKXSKRSEKIVO4SiUQSQv4fTdl3C6nr7PcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1 = corr_dim_data[1]\n",
    "data1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e8dc363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data4[data4 < 2.5].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "234428df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-02-12 10:32:39</th>\n",
       "      <td>0.388708</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.585741</td>\n",
       "      <td>0.226190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 10:42:39</th>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.549185</td>\n",
       "      <td>0.226190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 10:52:39</th>\n",
       "      <td>0.456721</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.579184</td>\n",
       "      <td>0.323551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 11:02:39</th>\n",
       "      <td>0.470881</td>\n",
       "      <td>0.456721</td>\n",
       "      <td>0.604150</td>\n",
       "      <td>0.335456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 11:12:39</th>\n",
       "      <td>0.388708</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.521124</td>\n",
       "      <td>0.226190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:22:39</th>\n",
       "      <td>0.825673</td>\n",
       "      <td>0.510663</td>\n",
       "      <td>0.549185</td>\n",
       "      <td>0.470881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:32:39</th>\n",
       "      <td>0.733274</td>\n",
       "      <td>0.549185</td>\n",
       "      <td>0.549185</td>\n",
       "      <td>0.470881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:42:39</th>\n",
       "      <td>0.890695</td>\n",
       "      <td>0.626070</td>\n",
       "      <td>0.510663</td>\n",
       "      <td>0.470881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:52:39</th>\n",
       "      <td>0.814544</td>\n",
       "      <td>0.587479</td>\n",
       "      <td>0.558808</td>\n",
       "      <td>0.470881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 06:02:39</th>\n",
       "      <td>0.848884</td>\n",
       "      <td>0.579184</td>\n",
       "      <td>0.567717</td>\n",
       "      <td>0.510663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>982 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1         2         3\n",
       "2004-02-12 10:32:39  0.388708  0.404762  0.585741  0.226190\n",
       "2004-02-12 10:42:39  0.345471  0.404762  0.549185  0.226190\n",
       "2004-02-12 10:52:39  0.456721  0.404762  0.579184  0.323551\n",
       "2004-02-12 11:02:39  0.470881  0.456721  0.604150  0.335456\n",
       "2004-02-12 11:12:39  0.388708  0.404762  0.521124  0.226190\n",
       "...                       ...       ...       ...       ...\n",
       "2004-02-19 05:22:39  0.825673  0.510663  0.549185  0.470881\n",
       "2004-02-19 05:32:39  0.733274  0.549185  0.549185  0.470881\n",
       "2004-02-19 05:42:39  0.890695  0.626070  0.510663  0.470881\n",
       "2004-02-19 05:52:39  0.814544  0.587479  0.558808  0.470881\n",
       "2004-02-19 06:02:39  0.848884  0.579184  0.567717  0.510663\n",
       "\n",
       "[982 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('E:/WorkSpace/cache/box_count_data.csv', index_col=0)#.reset_index()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce33fae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2004-02-12 10:32:39    0.388708\n",
       "2004-02-12 10:42:39    0.345471\n",
       "2004-02-12 10:52:39    0.456721\n",
       "2004-02-12 11:02:39    0.470881\n",
       "2004-02-12 11:12:39    0.388708\n",
       "                         ...   \n",
       "2004-02-19 05:22:39    0.825673\n",
       "2004-02-19 05:32:39    0.733274\n",
       "2004-02-19 05:42:39    0.890695\n",
       "2004-02-19 05:52:39    0.814544\n",
       "2004-02-19 06:02:39    0.848884\n",
       "Name: 0, Length: 982, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c182e6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bearing1</th>\n",
       "      <th>bearing2</th>\n",
       "      <th>bearing3</th>\n",
       "      <th>bearing4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-02-12 10:32:39</th>\n",
       "      <td>0.388708</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.585741</td>\n",
       "      <td>0.226190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 10:42:39</th>\n",
       "      <td>0.345471</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.549185</td>\n",
       "      <td>0.226190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 10:52:39</th>\n",
       "      <td>0.456721</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.579184</td>\n",
       "      <td>0.323551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 11:02:39</th>\n",
       "      <td>0.470881</td>\n",
       "      <td>0.456721</td>\n",
       "      <td>0.604150</td>\n",
       "      <td>0.335456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12 11:12:39</th>\n",
       "      <td>0.388708</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.521124</td>\n",
       "      <td>0.226190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:22:39</th>\n",
       "      <td>0.825673</td>\n",
       "      <td>0.510663</td>\n",
       "      <td>0.549185</td>\n",
       "      <td>0.470881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:32:39</th>\n",
       "      <td>0.733274</td>\n",
       "      <td>0.549185</td>\n",
       "      <td>0.549185</td>\n",
       "      <td>0.470881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:42:39</th>\n",
       "      <td>0.890695</td>\n",
       "      <td>0.626070</td>\n",
       "      <td>0.510663</td>\n",
       "      <td>0.470881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 05:52:39</th>\n",
       "      <td>0.814544</td>\n",
       "      <td>0.587479</td>\n",
       "      <td>0.558808</td>\n",
       "      <td>0.470881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19 06:02:39</th>\n",
       "      <td>0.848884</td>\n",
       "      <td>0.579184</td>\n",
       "      <td>0.567717</td>\n",
       "      <td>0.510663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>982 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bearing1  bearing2  bearing3  bearing4\n",
       "2004-02-12 10:32:39  0.388708  0.404762  0.585741  0.226190\n",
       "2004-02-12 10:42:39  0.345471  0.404762  0.549185  0.226190\n",
       "2004-02-12 10:52:39  0.456721  0.404762  0.579184  0.323551\n",
       "2004-02-12 11:02:39  0.470881  0.456721  0.604150  0.335456\n",
       "2004-02-12 11:12:39  0.388708  0.404762  0.521124  0.226190\n",
       "...                       ...       ...       ...       ...\n",
       "2004-02-19 05:22:39  0.825673  0.510663  0.549185  0.470881\n",
       "2004-02-19 05:32:39  0.733274  0.549185  0.549185  0.470881\n",
       "2004-02-19 05:42:39  0.890695  0.626070  0.510663  0.470881\n",
       "2004-02-19 05:52:39  0.814544  0.587479  0.558808  0.470881\n",
       "2004-02-19 06:02:39  0.848884  0.579184  0.567717  0.510663\n",
       "\n",
       "[982 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('E:/WorkSpace/cache/box_count_data.csv', index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb18c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets  import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0eeca81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = load_digits()\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0767c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15973223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4c8bc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90557c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': 1, 'two': 2, 'three': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = {'one': 1, 'two':2, 'three':3}\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feb1e0f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'one'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7c5caf1c8b1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'one'"
     ]
    }
   ],
   "source": [
    "s.one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0a1cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4261c49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5],\n",
       "       [2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix = np.array([[1,2,3,4,5], [2,3,4,5,6]]).reshape(2,5)\n",
    "my_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e0d4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"new.csv\", my_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "197c4070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4., 5.],\n",
       "       [2., 3., 4., 5., 6.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix = np.loadtxt(open(\"new.csv\",\"rb\"), delimiter=\",\", skiprows=0)\n",
    "my_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "152163de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f0ebea",
   "metadata": {},
   "source": [
    "# 东南大学数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de5d0e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9987277353689568\n",
      "{'C': 1000, 'kernel': 'linear'}\n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0        0.259107      0.002928         0.158775        0.001611       1   \n",
      "1        0.510635      0.003105         0.196886        0.000815       1   \n",
      "2        0.158376      0.002105         0.109510        0.000770      10   \n",
      "3        0.269858      0.001363         0.161380        0.001707      10   \n",
      "4        0.085378      0.002557         0.053252        0.001370     100   \n",
      "5        0.173137      0.002777         0.116892        0.002154     100   \n",
      "6        0.073384      0.013940         0.026548        0.000804    1000   \n",
      "7        0.094949      0.003303         0.059232        0.000800    1000   \n",
      "8        0.252531      0.041436         0.018350        0.000475       1   \n",
      "9        2.099812      0.499875         0.007770        0.000409      10   \n",
      "10       6.401278      2.112014         0.002990        0.000003     100   \n",
      "11      14.295806      7.853105         0.001199        0.000405    1000   \n",
      "\n",
      "   param_gamma param_kernel                                         params  \\\n",
      "0        0.001          rbf      {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
      "1       0.0001          rbf     {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
      "2        0.001          rbf     {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
      "3       0.0001          rbf    {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
      "4        0.001          rbf    {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
      "5       0.0001          rbf   {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
      "6        0.001          rbf   {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
      "7       0.0001          rbf  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
      "8          NaN       linear                   {'C': 1, 'kernel': 'linear'}   \n",
      "9          NaN       linear                  {'C': 10, 'kernel': 'linear'}   \n",
      "10         NaN       linear                 {'C': 100, 'kernel': 'linear'}   \n",
      "11         NaN       linear                {'C': 1000, 'kernel': 'linear'}   \n",
      "\n",
      "    split0_test_score  split1_test_score  split2_test_score  \\\n",
      "0            0.826972           0.816794           0.851145   \n",
      "1            0.680662           0.656489           0.676845   \n",
      "2            0.932570           0.933842           0.947837   \n",
      "3            0.788804           0.762087           0.736641   \n",
      "4            0.954198           0.965649           0.972010   \n",
      "5            0.933842           0.940204           0.949109   \n",
      "6            0.964377           0.978372           0.983461   \n",
      "7            0.958015           0.973282           0.973282   \n",
      "8            0.969466           0.979644           0.983461   \n",
      "9            0.991094           0.996183           1.000000   \n",
      "10           0.998728           0.998728           1.000000   \n",
      "11           0.998728           0.998728           1.000000   \n",
      "\n",
      "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
      "0            0.843511           0.832061         0.834097        0.012113   \n",
      "1            0.662850           0.669211         0.669211        0.008851   \n",
      "2            0.940204           0.930025         0.936896        0.006417   \n",
      "3            0.721374           0.712468         0.744275        0.027909   \n",
      "4            0.973282           0.966921         0.966412        0.006761   \n",
      "5            0.947837           0.933842         0.940967        0.006567   \n",
      "6            0.987277           0.980916         0.978880        0.007826   \n",
      "7            0.979644           0.972010         0.971247        0.007134   \n",
      "8            0.987277           0.983461         0.980662        0.006096   \n",
      "9            0.997455           0.992366         0.995420        0.003278   \n",
      "10           0.997455           0.996183         0.998219        0.001297   \n",
      "11           0.997455           0.998728         0.998728        0.000805   \n",
      "\n",
      "    rank_test_score  \n",
      "0                10  \n",
      "1                12  \n",
      "2                 9  \n",
      "3                11  \n",
      "4                 7  \n",
      "5                 8  \n",
      "6                 5  \n",
      "7                 6  \n",
      "8                 4  \n",
      "9                 3  \n",
      "10                2  \n",
      "11                1  \n"
     ]
    }
   ],
   "source": [
    "features = np.loadtxt('E:/WorkSpace/cache/SEU_gearset_20_0_Wavelet_features.csv', delimiter=\",\", skiprows=0)\n",
    "labels = np.loadtxt('E:/WorkSpace/cache/SEU_gearset_20_0_Wavelet_labels.csv', delimiter=\",\", skiprows=0)\n",
    "labels = np.where(labels == 1)[1]\n",
    "\n",
    "# 划分训练和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.25, random_state=15)\n",
    "\n",
    "# 使用网格搜索寻找最优参数\n",
    "model = SVC()\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                         'C': [1, 10, 100, 1000]},\n",
    "                        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "\"\"\"\n",
    "用表格查看训练信息\n",
    "\"\"\"\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "# 查看其他指标的结果和参数，比如这里按平均准确率排序\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "610a6d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259107</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.158775</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.826972</td>\n",
       "      <td>0.816794</td>\n",
       "      <td>0.851145</td>\n",
       "      <td>0.843511</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.834097</td>\n",
       "      <td>0.012113</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.510635</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.196886</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.680662</td>\n",
       "      <td>0.656489</td>\n",
       "      <td>0.676845</td>\n",
       "      <td>0.662850</td>\n",
       "      <td>0.669211</td>\n",
       "      <td>0.669211</td>\n",
       "      <td>0.008851</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.158376</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.109510</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.932570</td>\n",
       "      <td>0.933842</td>\n",
       "      <td>0.947837</td>\n",
       "      <td>0.940204</td>\n",
       "      <td>0.930025</td>\n",
       "      <td>0.936896</td>\n",
       "      <td>0.006417</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.269858</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.161380</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.788804</td>\n",
       "      <td>0.762087</td>\n",
       "      <td>0.736641</td>\n",
       "      <td>0.721374</td>\n",
       "      <td>0.712468</td>\n",
       "      <td>0.744275</td>\n",
       "      <td>0.027909</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085378</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.053252</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>0.965649</td>\n",
       "      <td>0.972010</td>\n",
       "      <td>0.973282</td>\n",
       "      <td>0.966921</td>\n",
       "      <td>0.966412</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.173137</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.116892</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.933842</td>\n",
       "      <td>0.940204</td>\n",
       "      <td>0.949109</td>\n",
       "      <td>0.947837</td>\n",
       "      <td>0.933842</td>\n",
       "      <td>0.940967</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.073384</td>\n",
       "      <td>0.013940</td>\n",
       "      <td>0.026548</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.964377</td>\n",
       "      <td>0.978372</td>\n",
       "      <td>0.983461</td>\n",
       "      <td>0.987277</td>\n",
       "      <td>0.980916</td>\n",
       "      <td>0.978880</td>\n",
       "      <td>0.007826</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.094949</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.059232</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.958015</td>\n",
       "      <td>0.973282</td>\n",
       "      <td>0.973282</td>\n",
       "      <td>0.979644</td>\n",
       "      <td>0.972010</td>\n",
       "      <td>0.971247</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.252531</td>\n",
       "      <td>0.041436</td>\n",
       "      <td>0.018350</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.969466</td>\n",
       "      <td>0.979644</td>\n",
       "      <td>0.983461</td>\n",
       "      <td>0.987277</td>\n",
       "      <td>0.983461</td>\n",
       "      <td>0.980662</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.099812</td>\n",
       "      <td>0.499875</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>0.991094</td>\n",
       "      <td>0.996183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.992366</td>\n",
       "      <td>0.995420</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.401278</td>\n",
       "      <td>2.112014</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 100, 'kernel': 'linear'}</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.996183</td>\n",
       "      <td>0.998219</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.295806</td>\n",
       "      <td>7.853105</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1000, 'kernel': 'linear'}</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.259107      0.002928         0.158775        0.001611       1   \n",
       "1        0.510635      0.003105         0.196886        0.000815       1   \n",
       "2        0.158376      0.002105         0.109510        0.000770      10   \n",
       "3        0.269858      0.001363         0.161380        0.001707      10   \n",
       "4        0.085378      0.002557         0.053252        0.001370     100   \n",
       "5        0.173137      0.002777         0.116892        0.002154     100   \n",
       "6        0.073384      0.013940         0.026548        0.000804    1000   \n",
       "7        0.094949      0.003303         0.059232        0.000800    1000   \n",
       "8        0.252531      0.041436         0.018350        0.000475       1   \n",
       "9        2.099812      0.499875         0.007770        0.000409      10   \n",
       "10       6.401278      2.112014         0.002990        0.000003     100   \n",
       "11      14.295806      7.853105         0.001199        0.000405    1000   \n",
       "\n",
       "   param_gamma param_kernel                                         params  \\\n",
       "0        0.001          rbf      {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "1       0.0001          rbf     {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "2        0.001          rbf     {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "3       0.0001          rbf    {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "4        0.001          rbf    {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "5       0.0001          rbf   {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "6        0.001          rbf   {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "7       0.0001          rbf  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "8          NaN       linear                   {'C': 1, 'kernel': 'linear'}   \n",
       "9          NaN       linear                  {'C': 10, 'kernel': 'linear'}   \n",
       "10         NaN       linear                 {'C': 100, 'kernel': 'linear'}   \n",
       "11         NaN       linear                {'C': 1000, 'kernel': 'linear'}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.826972           0.816794           0.851145   \n",
       "1            0.680662           0.656489           0.676845   \n",
       "2            0.932570           0.933842           0.947837   \n",
       "3            0.788804           0.762087           0.736641   \n",
       "4            0.954198           0.965649           0.972010   \n",
       "5            0.933842           0.940204           0.949109   \n",
       "6            0.964377           0.978372           0.983461   \n",
       "7            0.958015           0.973282           0.973282   \n",
       "8            0.969466           0.979644           0.983461   \n",
       "9            0.991094           0.996183           1.000000   \n",
       "10           0.998728           0.998728           1.000000   \n",
       "11           0.998728           0.998728           1.000000   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.843511           0.832061         0.834097        0.012113   \n",
       "1            0.662850           0.669211         0.669211        0.008851   \n",
       "2            0.940204           0.930025         0.936896        0.006417   \n",
       "3            0.721374           0.712468         0.744275        0.027909   \n",
       "4            0.973282           0.966921         0.966412        0.006761   \n",
       "5            0.947837           0.933842         0.940967        0.006567   \n",
       "6            0.987277           0.980916         0.978880        0.007826   \n",
       "7            0.979644           0.972010         0.971247        0.007134   \n",
       "8            0.987277           0.983461         0.980662        0.006096   \n",
       "9            0.997455           0.992366         0.995420        0.003278   \n",
       "10           0.997455           0.996183         0.998219        0.001297   \n",
       "11           0.997455           0.998728         0.998728        0.000805   \n",
       "\n",
       "    rank_test_score  \n",
       "0                10  \n",
       "1                12  \n",
       "2                 9  \n",
       "3                11  \n",
       "4                 7  \n",
       "5                 8  \n",
       "6                 5  \n",
       "7                 6  \n",
       "8                 4  \n",
       "9                 3  \n",
       "10                2  \n",
       "11                1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fe12b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.9969465648854962\n",
      "训练集： 0.9979643765903308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 使用逻辑回归进行分类预测\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000, C=1000)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e573b0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1310, 64), (3930, 64))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1916c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.999236641221374\n",
      "训练集： 1.0\n"
     ]
    }
   ],
   "source": [
    "# 使用随机森林进行分类预测\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=5, min_samples_split=10)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3ef9292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.9961832061068703\n",
      "训练集： 1.0\n"
     ]
    }
   ],
   "source": [
    "# 使用提升树进行分类预测\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1,min_samples_split=5, max_depth=5)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d956d772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.999236641221374\n",
      "训练集： 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.1, max_depth=9, \\\n",
    "                                 max_features=0.9000000000000001, \\\n",
    "                                 min_samples_leaf=17, min_samples_split=5, \\\n",
    "                                 n_estimators=100, subsample=0.55)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c9c50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.loadtxt('E:/WorkSpace/cache/SEU_bearingset_20_0_Wavelet_features.csv', delimiter=\",\", skiprows=0)\n",
    "labels = np.loadtxt('E:/WorkSpace/cache/SEU_bearingset_20_0_Wavelet_labels.csv', delimiter=\",\", skiprows=0)\n",
    "labels = np.where(labels == 1)[1]\n",
    "\n",
    "# 划分训练和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b37b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.9984732824427481\n",
      "训练集： 0.999236641221374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 使用逻辑回归进行分类预测\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000, C=1000)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0538d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 1.0\n",
      "训练集： 1.0\n"
     ]
    }
   ],
   "source": [
    "# 使用随机森林进行分类预测\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=5, min_samples_split=10)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80aa900e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 1.0\n",
      "训练集： 1.0\n"
     ]
    }
   ],
   "source": [
    "# 使用提升树进行分类预测\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1,min_samples_split=5, max_depth=5)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d0f07",
   "metadata": {},
   "source": [
    "# 江南大学数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a07dbc",
   "metadata": {},
   "source": [
    "## 转速600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68fd8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11c1e44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2250, 8), (751, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.loadtxt('E:/WorkSpace/cache/JNU_600_Wavelet_features.csv', delimiter=\",\", skiprows=0)\n",
    "labels = np.loadtxt('E:/WorkSpace/cache/JNU_600_Wavelet_labels.csv', delimiter=\",\", skiprows=0)\n",
    "labels = np.where(labels == 1)[1]\n",
    "\n",
    "# 划分训练和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.25, random_state=15)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aab324",
   "metadata": {},
   "source": [
    "### 使用逻辑回归进行分类预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b9c27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.7643142476697736\n",
      "训练集： 0.772\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, max_iter=1000, C=1000)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c632fcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.7403462050599201\n",
      "训练集： 0.7462222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89276801",
   "metadata": {},
   "source": [
    "### GridSearch寻找最优参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b1070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy: 0.7723035952063915\n",
      "train set accuracy: 0.7751111111111111\n",
      "0.764\n",
      "{'C': 0.1, 'max_iter': 200, 'multi_class': 'auto', 'penalty': 'none'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.76088889        nan 0.74311111        nan 0.73555556        nan\n",
      " 0.71511111        nan 0.76088889        nan 0.74311111        nan\n",
      " 0.764             nan 0.74622222        nan 0.73555556        nan\n",
      " 0.71511111        nan 0.764             nan 0.74622222        nan\n",
      " 0.764             nan 0.74533333        nan 0.73555556        nan\n",
      " 0.71511111        nan 0.764             nan 0.74533333        nan\n",
      " 0.764             nan 0.74533333        nan 0.73555556        nan\n",
      " 0.71511111        nan 0.764             nan 0.74533333        nan\n",
      " 0.76088889        nan 0.75511111        nan 0.73555556        nan\n",
      " 0.73155556        nan 0.76088889        nan 0.75511111        nan\n",
      " 0.764             nan 0.76              nan 0.73555556        nan\n",
      " 0.73155556        nan 0.764             nan 0.76              nan\n",
      " 0.764             nan 0.76              nan 0.73555556        nan\n",
      " 0.73155556        nan 0.764             nan 0.76              nan\n",
      " 0.764             nan 0.76              nan 0.73555556        nan\n",
      " 0.73155556        nan 0.764             nan 0.76              nan\n",
      " 0.76088889        nan 0.75333333        nan 0.73555556        nan\n",
      " 0.73511111        nan 0.76088889        nan 0.75333333        nan\n",
      " 0.764             nan 0.75822222        nan 0.73555556        nan\n",
      " 0.73511111        nan 0.764             nan 0.75822222        nan\n",
      " 0.764             nan 0.76266667        nan 0.73555556        nan\n",
      " 0.73511111        nan 0.764             nan 0.76266667        nan\n",
      " 0.764             nan 0.76266667        nan 0.73555556        nan\n",
      " 0.73511111        nan 0.764             nan 0.76266667        nan\n",
      " 0.76088889        nan 0.75777778        nan 0.73555556        nan\n",
      " 0.73555556        nan 0.76088889        nan 0.75777778        nan\n",
      " 0.764             nan 0.76133333        nan 0.73555556        nan\n",
      " 0.73555556        nan 0.764             nan 0.76133333        nan\n",
      " 0.764             nan 0.764             nan 0.73555556        nan\n",
      " 0.73555556        nan 0.764             nan 0.764             nan\n",
      " 0.764             nan 0.76355556        nan 0.73555556        nan\n",
      " 0.73555556        nan 0.764             nan 0.76355556        nan\n",
      " 0.76088889        nan 0.75466667        nan 0.73555556        nan\n",
      " 0.73555556        nan 0.76088889        nan 0.75466667        nan\n",
      " 0.764             nan 0.76222222        nan 0.73555556        nan\n",
      " 0.73555556        nan 0.764             nan 0.76222222        nan\n",
      " 0.764             nan 0.76355556        nan 0.73555556        nan\n",
      " 0.73555556        nan 0.764             nan 0.76355556        nan\n",
      " 0.764             nan 0.76355556        nan 0.73555556        nan\n",
      " 0.73555556        nan 0.764             nan 0.76355556        nan]\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "tuned_parameters = [\n",
    "        {'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "         'C':[0.1, 1, 10, 100, 1000],\n",
    "         'max_iter':[100, 200, 400, 800],\n",
    "         'multi_class':['auto', 'ovr', 'multinomial']}\n",
    "    ]\n",
    "clf = GridSearchCV(model, tuned_parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "best_model = clf.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print('test set accuracy:', accuracy_score(Y_test, y_pred))\n",
    "print('train set accuracy:', best_model.score(X_train, Y_train) )\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1cf9ea",
   "metadata": {},
   "source": [
    "### 使用支持向量机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761cf919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8622222222222222\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y_tes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-12c29aab8a86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test set accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_tes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train set accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_tes' is not defined"
     ]
    }
   ],
   "source": [
    "# 使用网格搜索寻找最优参数\n",
    "model = SVC()\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                         'C': [1, 10, 100, 1000]},\n",
    "                        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "best_model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "633ebeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy: 0.8908122503328895\n",
      "train set accuracy: 0.9182222222222223\n"
     ]
    }
   ],
   "source": [
    "print('test set accuracy:', best_model.score(X_test, Y_test))\n",
    "print('train set accuracy:', best_model.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa2da398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   0.3s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   0.3s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   0.3s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   0.3s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   0.3s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   0.3s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   0.3s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   0.3s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   0.3s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   0.3s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   0.3s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   0.3s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   0.3s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   0.3s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   0.3s\n",
      "0.8995555555555557\n",
      "{'max_depth': 7, 'max_features': 0.5, 'min_samples_split': 3}\n",
      "test set accuracy: 0.9014647137150466\n",
      "train set accuracy: 0.9497777777777778\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "tuned_parameters = [\n",
    "        {# 'n_estimators': [50, 100, 200, 400]\n",
    "         'max_features':[0.1, 0.2, 0.4, 0.5, 0.6, 0.8],\n",
    "         'max_depth':[3,4,5,6,7],\n",
    "         'min_samples_split':[3,4,5,6,7],\n",
    "         # 'min_samples_leaf':[3,4,5,6,7]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters, verbose = 3)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "best_model = clf.best_estimator_\n",
    "print('test set accuracy:', best_model.score(X_test, Y_test))\n",
    "print('train set accuracy:', best_model.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c94eda1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.9027962716378163\n",
      "训练集： 0.9551111111111111\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=8, max_features=0.4, n_estimators=400, min_samples_leaf=3, min_samples_split=2)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ff17430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.8988015978695073\n",
      "训练集： 0.9435555555555556\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=7, max_features=0.5, n_estimators=400, min_samples_leaf=3, min_samples_split=6)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec145dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.1s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "0.9111111111111111\n",
      "{'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 5}\n",
      "test set accuracy: 0.914780292942743\n",
      "train set accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "tuned_parameters = [\n",
    "        {'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        # 'n_estimators': [100, 200, 400, 800],\n",
    "         'max_depth':[3,4,5,6,7],\n",
    "        # 'min_samples_split':[3,4,5,6,7],\n",
    "         'min_samples_leaf':[3,4,5,6,7]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters, verbose=2)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "best_model = clf.best_estimator_\n",
    "print('test set accuracy:', best_model.score(X_test, Y_test))\n",
    "print('train set accuracy:', best_model.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21eed57",
   "metadata": {},
   "source": [
    "## 转速800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c63651",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.loadtxt('E:/WorkSpace/cache/JNU_800_Wavelet_features.csv', delimiter=\",\", skiprows=0)\n",
    "labels = np.loadtxt('E:/WorkSpace/cache/JNU_800_Wavelet_labels.csv', delimiter=\",\", skiprows=0)\n",
    "labels = np.where(labels == 1)[1]\n",
    "\n",
    "# 划分训练和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e355961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.9320905459387483\n",
      "训练集： 0.9604444444444444\n"
     ]
    }
   ],
   "source": [
    "# 使用逻辑回归进行分类预测\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = RandomForestClassifier(max_depth=8, max_features=0.4, n_estimators=400, min_samples_leaf=3, min_samples_split=2)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3165b3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.7403462050599201\n",
      "训练集： 0.7457777777777778\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "485f0b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.762982689747004\n",
      "训练集： 0.7408888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a738eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.9280958721704394\n",
      "训练集： 0.9848888888888889\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))\n",
    "# print(clf.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6ad7843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.9241011984021305\n",
      "训练集： 0.9822222222222222\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.1, max_depth=3, min_samples_leaf=5)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1efa3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "0.9235555555555555\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 5}\n",
      "test set accuracy: 0.9201065246338216\n",
      "train set accuracy: 0.9826666666666667\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "tuned_parameters = [\n",
    "        {'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        # 'n_estimators': [100, 200, 400, 800],\n",
    "         'max_depth':[3,4,5,6,7],\n",
    "        # 'min_samples_split':[3,4,5,6,7],\n",
    "         'min_samples_leaf':[3,4,5,6,7]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters, verbose=2)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "best_model = clf.best_estimator_\n",
    "print('test set accuracy:', best_model.score(X_test, Y_test))\n",
    "print('train set accuracy:', best_model.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5454ada",
   "metadata": {},
   "source": [
    "### 转速1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c7cc91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.loadtxt('E:/WorkSpace/cache/JNU_1000_Wavelet_features.csv', delimiter=\",\", skiprows=0)\n",
    "labels = np.loadtxt('E:/WorkSpace/cache/JNU_1000_Wavelet_labels.csv', delimiter=\",\", skiprows=0)\n",
    "labels = np.where(labels == 1)[1]\n",
    "\n",
    "# 划分训练和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c784a069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.8229027962716379\n",
      "训练集： 0.8328888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 使用逻辑回归进行分类预测\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "677384bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.7603195739014648\n",
      "训练集： 0.7924444444444444\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b48d4d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.8934753661784287\n",
      "训练集： 0.9591111111111111\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=8, max_features=0.4, n_estimators=400, min_samples_leaf=3, min_samples_split=2)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba21818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.8455392809587217\n",
      "训练集： 0.8551111111111112\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=10)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f22cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.8455392809587217\n",
      "训练集： 0.8528888888888889\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b877b99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.3s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.3s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   0.3s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   0.3s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   0.3s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   0.3s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   0.3s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   0.3s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   0.3s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   0.3s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   0.3s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   0.3s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   0.3s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   0.3s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   0.3s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   0.3s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   0.3s\n",
      "0.8946666666666667\n",
      "{'max_depth': 7, 'max_features': 0.4, 'min_samples_split': 6}\n",
      "test set accuracy: 0.8961384820239681\n",
      "train set accuracy: 0.9484444444444444\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "tuned_parameters = [\n",
    "        {# 'n_estimators': [50, 100, 200, 400]\n",
    "         'max_features':[0.1, 0.2, 0.4, 0.5, 0.6, 0.8],\n",
    "         'max_depth':[3,4,5,6,7],\n",
    "         'min_samples_split':[3,4,5,6,7],\n",
    "         # 'min_samples_leaf':[3,4,5,6,7]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters, verbose = 3)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "best_model = clf.best_estimator_\n",
    "print('test set accuracy:', best_model.score(X_test, Y_test))\n",
    "print('train set accuracy:', best_model.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c200f344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.3s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   1.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   2.5s\n",
      "0.896888888888889\n",
      "{'learning_rate': 0.2, 'max_depth': 4, 'min_samples_leaf': 3}\n",
      "test set accuracy: 0.9094540612516645\n",
      "train set accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "tuned_parameters = [\n",
    "        {'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        # 'n_estimators': [100, 200, 400, 800],\n",
    "         'max_depth':[3,4,5,6,7],\n",
    "        # 'min_samples_split':[3,4,5,6,7],\n",
    "         'min_samples_leaf':[3,4,5,6,7]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters, verbose=2)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "best_model = clf.best_estimator_\n",
    "print('test set accuracy:', best_model.score(X_test, Y_test))\n",
    "print('train set accuracy:', best_model.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090680d",
   "metadata": {},
   "source": [
    "### 所有数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95dfdbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.loadtxt('E:/WorkSpace/cache/JNU_Wavelet_features.csv', delimiter=\",\", skiprows=0)\n",
    "labels = np.loadtxt('E:/WorkSpace/cache/JNU_Wavelet_labels.csv', delimiter=\",\", skiprows=0)\n",
    "labels = np.where(labels == 1)[1]\n",
    "\n",
    "# 划分训练和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8356626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.7347845402043536\n",
      "训练集： 0.7178613744075829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 使用逻辑回归进行分类预测\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ad9408a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.729009329187028\n",
      "训练集： 0.7340047393364929\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df08e558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.8751665926254998\n",
      "训练集： 0.9028436018957346\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=8, max_features=0.4, n_estimators=400, min_samples_leaf=3, min_samples_split=2)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acbc6dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.1, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, max_features=0.2, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=3, max_features=0.4, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.3s\n",
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.3s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=3; total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.3s\n",
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.3s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=4; total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.3s\n",
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.3s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=5; total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.3s\n",
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.3s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=6; total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.3s\n",
      "[CV 5/5] END max_depth=3, max_features=0.5, min_samples_split=7; total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.3s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.3s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=3; total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.3s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.3s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=4; total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.3s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.3s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=5; total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.3s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.3s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=6; total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.3s\n",
      "[CV 3/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.3s\n",
      "[CV 5/5] END max_depth=3, max_features=0.6, min_samples_split=7; total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.5s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.5s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.5s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.5s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=3; total time=   0.5s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.5s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.5s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.5s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.5s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=4; total time=   0.5s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.5s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.5s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.5s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.5s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=5; total time=   0.5s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.5s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.5s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.5s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.5s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=6; total time=   0.5s\n",
      "[CV 1/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.5s\n",
      "[CV 2/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.5s\n",
      "[CV 3/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.5s\n",
      "[CV 4/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.5s\n",
      "[CV 5/5] END max_depth=3, max_features=0.8, min_samples_split=7; total time=   0.5s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.1, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=3; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=4; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=6; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.1s\n",
      "[CV 2/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.1s\n",
      "[CV 3/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.1s\n",
      "[CV 4/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=4, max_features=0.2, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.3s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.3s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.3s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.3s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=3; total time=   0.3s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.3s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.3s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.3s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.3s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=4; total time=   0.3s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.3s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.3s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.3s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.3s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=5; total time=   0.3s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.3s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.3s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.3s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.3s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=6; total time=   0.3s\n",
      "[CV 1/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.3s\n",
      "[CV 2/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.3s\n",
      "[CV 3/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.3s\n",
      "[CV 4/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.3s\n",
      "[CV 5/5] END max_depth=4, max_features=0.4, min_samples_split=7; total time=   0.3s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=3; total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=4; total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=5; total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=6; total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, max_features=0.5, min_samples_split=7; total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=3; total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=4; total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=5; total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=6; total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.4s\n",
      "[CV 2/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.4s\n",
      "[CV 3/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.4s\n",
      "[CV 4/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.4s\n",
      "[CV 5/5] END max_depth=4, max_features=0.6, min_samples_split=7; total time=   0.4s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.6s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.6s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.6s\n",
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.6s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=3; total time=   0.6s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.6s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.6s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.6s\n",
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.6s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=4; total time=   0.6s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.6s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.6s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.6s\n",
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.6s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=5; total time=   0.6s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.6s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.6s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.6s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=6; total time=   0.6s\n",
      "[CV 1/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.6s\n",
      "[CV 2/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.6s\n",
      "[CV 3/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.6s\n",
      "[CV 4/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.6s\n",
      "[CV 5/5] END max_depth=4, max_features=0.8, min_samples_split=7; total time=   0.6s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=6; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=5; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=0.2, min_samples_split=7; total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.4s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.4s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.4s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.4s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=3; total time=   0.4s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.4s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.4s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.4s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.4s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=4; total time=   0.4s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.4s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.4s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.4s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.4s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=5; total time=   0.4s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.4s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.4s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.4s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.4s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=6; total time=   0.4s\n",
      "[CV 1/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.4s\n",
      "[CV 2/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.4s\n",
      "[CV 3/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.4s\n",
      "[CV 4/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.4s\n",
      "[CV 5/5] END max_depth=5, max_features=0.4, min_samples_split=7; total time=   0.4s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.5s\n",
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.5s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.5s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.5s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=3; total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.5s\n",
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.5s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.5s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.5s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=4; total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.5s\n",
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.5s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.5s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.5s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=5; total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.5s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.5s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.5s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=6; total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.5s\n",
      "[CV 2/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.5s\n",
      "[CV 3/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.5s\n",
      "[CV 4/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.5s\n",
      "[CV 5/5] END max_depth=5, max_features=0.5, min_samples_split=7; total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.5s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.5s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.5s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.5s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=3; total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.5s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.5s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.5s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.5s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=4; total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.5s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.5s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.5s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.5s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=5; total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.5s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.5s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.5s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.5s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=6; total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.5s\n",
      "[CV 2/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.5s\n",
      "[CV 3/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.5s\n",
      "[CV 4/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.5s\n",
      "[CV 5/5] END max_depth=5, max_features=0.6, min_samples_split=7; total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.7s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.7s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.7s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.7s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=3; total time=   0.7s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.7s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.7s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.7s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.7s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=4; total time=   0.7s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.7s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.7s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.7s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.7s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=5; total time=   0.7s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.7s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.7s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.7s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.7s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=6; total time=   0.7s\n",
      "[CV 1/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.7s\n",
      "[CV 2/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.7s\n",
      "[CV 3/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.7s\n",
      "[CV 4/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.7s\n",
      "[CV 5/5] END max_depth=5, max_features=0.8, min_samples_split=7; total time=   0.7s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=6, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.4s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.4s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.4s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.4s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=3; total time=   0.4s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.4s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.5s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.4s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.4s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=4; total time=   0.4s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.4s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.5s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.4s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.4s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=5; total time=   0.4s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.4s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.4s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.4s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.4s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=6; total time=   0.4s\n",
      "[CV 1/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.5s\n",
      "[CV 2/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.4s\n",
      "[CV 3/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.4s\n",
      "[CV 4/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.4s\n",
      "[CV 5/5] END max_depth=6, max_features=0.4, min_samples_split=7; total time=   0.4s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.6s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.6s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.6s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.6s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=3; total time=   0.6s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.6s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.6s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.6s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.6s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=4; total time=   0.6s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.6s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.6s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.6s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.6s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=5; total time=   0.6s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.6s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.6s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.6s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.6s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=6; total time=   0.6s\n",
      "[CV 1/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.6s\n",
      "[CV 2/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.6s\n",
      "[CV 3/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.6s\n",
      "[CV 4/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.6s\n",
      "[CV 5/5] END max_depth=6, max_features=0.5, min_samples_split=7; total time=   0.6s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.6s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.6s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.6s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.6s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=3; total time=   0.6s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.6s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.6s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.6s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.6s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=4; total time=   0.6s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.6s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.6s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.6s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.6s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=5; total time=   0.6s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.6s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.6s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.6s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.6s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=6; total time=   0.6s\n",
      "[CV 1/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.6s\n",
      "[CV 2/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.6s\n",
      "[CV 3/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.6s\n",
      "[CV 4/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.6s\n",
      "[CV 5/5] END max_depth=6, max_features=0.6, min_samples_split=7; total time=   0.6s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.8s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.8s\n",
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.9s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.9s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=3; total time=   0.8s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.8s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.8s\n",
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.9s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.8s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=4; total time=   0.8s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.8s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.8s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.8s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=5; total time=   0.9s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.9s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.8s\n",
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.8s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.8s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=6; total time=   0.8s\n",
      "[CV 1/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.8s\n",
      "[CV 2/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.9s\n",
      "[CV 3/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.8s\n",
      "[CV 4/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.8s\n",
      "[CV 5/5] END max_depth=6, max_features=0.8, min_samples_split=7; total time=   0.8s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.1, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=3; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=4; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=5; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=6; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 2/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, max_features=0.2, min_samples_split=7; total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.5s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.5s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.5s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.5s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=3; total time=   0.5s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.5s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.5s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.5s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.5s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=4; total time=   0.5s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.5s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.5s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.5s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.5s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=5; total time=   0.5s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.5s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.5s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.5s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.5s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=6; total time=   0.5s\n",
      "[CV 1/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.5s\n",
      "[CV 2/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.5s\n",
      "[CV 3/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.5s\n",
      "[CV 4/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.5s\n",
      "[CV 5/5] END max_depth=7, max_features=0.4, min_samples_split=7; total time=   0.5s\n",
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.7s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.7s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.7s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.7s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=3; total time=   0.7s\n",
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.7s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.7s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.7s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.7s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=4; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.7s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.7s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.7s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.7s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=5; total time=   0.7s\n",
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.7s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.7s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.7s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.7s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=6; total time=   0.7s\n",
      "[CV 1/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.7s\n",
      "[CV 2/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.7s\n",
      "[CV 3/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.7s\n",
      "[CV 4/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.7s\n",
      "[CV 5/5] END max_depth=7, max_features=0.5, min_samples_split=7; total time=   0.7s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.7s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.7s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.7s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.7s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=3; total time=   0.7s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.7s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.7s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.7s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.7s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=4; total time=   0.7s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.7s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.7s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.7s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.7s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=5; total time=   0.7s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.7s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.7s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.7s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.7s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=6; total time=   0.7s\n",
      "[CV 1/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.7s\n",
      "[CV 2/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.7s\n",
      "[CV 3/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.7s\n",
      "[CV 4/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.7s\n",
      "[CV 5/5] END max_depth=7, max_features=0.6, min_samples_split=7; total time=   0.7s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   1.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   1.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   1.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   1.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=3; total time=   1.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   1.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   1.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   1.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   1.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=4; total time=   1.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   1.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   1.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   1.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   1.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=5; total time=   1.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   1.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   1.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   1.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   1.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=6; total time=   1.0s\n",
      "[CV 1/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   1.0s\n",
      "[CV 2/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   1.0s\n",
      "[CV 3/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   1.0s\n",
      "[CV 4/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   1.0s\n",
      "[CV 5/5] END max_depth=7, max_features=0.8, min_samples_split=7; total time=   1.0s\n",
      "0.8496764536557283\n",
      "{'max_depth': 7, 'max_features': 0.5, 'min_samples_split': 4}\n",
      "test set accuracy: 0.8613949355841848\n",
      "train set accuracy: 0.8824052132701422\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "tuned_parameters = [\n",
    "        {# 'n_estimators': [50, 100, 200, 400]\n",
    "         'max_features':[0.1, 0.2, 0.4, 0.5, 0.6, 0.8],\n",
    "         'max_depth':[3,4,5,6,7],\n",
    "         'min_samples_split':[3,4,5,6,7],\n",
    "         # 'min_samples_leaf':[3,4,5,6,7]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters, verbose = 3)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "best_model = clf.best_estimator_\n",
    "print('test set accuracy:', best_model.score(X_test, Y_test))\n",
    "print('train set accuracy:', best_model.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4193c0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   4.8s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=3; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=4; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=6; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=4; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=5; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=6; total time=   7.0s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   8.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   8.2s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   8.2s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   8.2s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=3; total time=   8.2s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   8.2s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5; total time=   8.2s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   8.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=7; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   3.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   3.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   3.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=3; total time=   3.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   3.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   3.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=4; total time=   3.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   3.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   3.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   3.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   4.8s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   4.8s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=3; total time=   4.8s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   4.8s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   4.8s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   4.8s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=5; total time=   4.8s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   4.8s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   4.8s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=6; total time=   4.8s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   5.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   5.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=4; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   5.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=6; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=7; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   7.1s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   7.1s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   7.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   7.1s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   7.0s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=5; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   8.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   8.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3; total time=   8.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   8.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   8.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   8.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=4; total time=   8.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   8.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   8.0s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   8.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   3.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=3; total time=   3.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   3.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   3.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   3.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   5.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   5.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   5.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   5.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=3; total time=   5.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   5.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   5.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=4; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   5.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   5.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=6; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=5; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=6; total time=   7.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   8.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   8.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   8.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   8.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=3; total time=   8.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=4; total time=   8.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   8.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   8.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   8.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=6; total time=   8.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=4; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   3.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   3.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=5; total time=   3.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   3.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   3.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=6; total time=   3.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   3.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   3.6s\n",
      "[CV] END .learning_rate=0.2, max_depth=3, min_samples_leaf=7; total time=   3.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   4.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   4.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=3; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   4.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=4; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   4.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=5; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=6; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   4.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=4, min_samples_leaf=7; total time=   4.7s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   5.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   5.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=3; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   5.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   5.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=4; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   5.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=5; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   5.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   5.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   5.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=6; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   5.8s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=5, min_samples_leaf=7; total time=   5.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=3; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=4; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   6.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   6.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   6.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=5; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   6.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=6; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   7.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=6, min_samples_leaf=7; total time=   6.9s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   8.2s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=3; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=4; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=5; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   8.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   8.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=6; total time=   8.1s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "[CV] END .learning_rate=0.2, max_depth=7, min_samples_leaf=7; total time=   8.0s\n",
      "0.8942527071853498\n",
      "{'learning_rate': 0.2, 'max_depth': 6, 'min_samples_leaf': 6}\n",
      "test set accuracy: 0.902265659706797\n",
      "train set accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "tuned_parameters = [\n",
    "        {'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        # 'n_estimators': [100, 200, 400, 800],\n",
    "         'max_depth':[3,4,5,6,7],\n",
    "        # 'min_samples_split':[3,4,5,6,7],\n",
    "         'min_samples_leaf':[3,4,5,6,7]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters, verbose=2)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "best_model = clf.best_estimator_\n",
    "print('test set accuracy:', best_model.score(X_test, Y_test))\n",
    "print('train set accuracy:', best_model.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a525deae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFile\\anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8915879047070756\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8945491131397866\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8967711160457273\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8992893055898236\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.8992893055898236\n",
      "\n",
      "Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=0.1, max_depth=9, max_features=0.45, min_samples_leaf=9, min_samples_split=17, n_estimators=100, subsample=0.6000000000000001)\n",
      "0.9067081297201244\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, n_jobs=-1)\n",
    "tpot.fit(X_train, Y_train)\n",
    "print(tpot.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e2d16df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.9133718347401155\n",
      "训练集： 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.1, max_depth=9, max_features=0.45, min_samples_leaf=9, min_samples_split=20, n_estimators=300, subsample=0.6)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('测试集：', clf.score(X_test, Y_test))\n",
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d65906d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2251,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbd7345c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 347, 1: 1179, 3: 358, 0: 367})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import  Counter\n",
    "Counter(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "804b6e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1133, 2: 1153, 1: 3324, 3: 1142})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03cc02c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1500, 1: 4503, 2: 1500, 3: 1500})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "68304802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 0.1,\n",
       " ...]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = [0.3 if label == 1 else 0.1 for label in Y_train]\n",
    "sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e004580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 3428, 1: 3324})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ac0b9f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集： 1.0\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train, sample_weight)\n",
    "# print('测试集：', clf.score(X_test, Y_test,sample_weight ))\n",
    "print('训练集：', clf.score(X_train, Y_train, sample_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0207dbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.947494033412888\n"
     ]
    }
   ],
   "source": [
    "test_sample_weight = [0.3 if label == 1 else 0.1 for label in Y_test]\n",
    "print('测试集：', clf.score(X_test, Y_test,test_sample_weight ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b5b854cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集： 0.9120390937361172\n"
     ]
    }
   ],
   "source": [
    "print('测试集：', clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a2564164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集： 1.0\n"
     ]
    }
   ],
   "source": [
    "print('训练集：', clf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a776fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
